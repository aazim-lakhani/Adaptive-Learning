{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Omniscient Policy / Oracle\n",
    "\n",
    "This notebook represents an omniscient policy that knows all of the probability distributions. This algorithm knows, every step of the way, the best decision based on its knowledge of the true distributions. It does not have to learn anything. The oracle has optimal parameters $\\theta$, hence it is expected to maximize reward in fewer rounds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure / validate these before you run: File Path, alpha, confidence_threshold ,to_csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Context Shape :  (100, 10)\n",
      "Content Context Shape :  (329, 9)\n",
      "**********************************\n",
      "     S_V   S_T   S_D   S_P   S_S  S_AT   S_L   S_A  S_SE  S_PA\n",
      "0   0.87  0.82  0.88  0.36  0.60  0.06  0.66  0.56  0.66  0.07\n",
      "1   0.60  0.00  0.97  0.26  0.68  0.19  0.77  0.09  0.57  0.41\n",
      "2   0.53  0.15  0.24  0.23  0.91  0.68  0.22  0.50  0.92  0.85\n",
      "3   0.11  0.28  0.61  0.77  0.21  0.53  0.75  0.87  0.69  0.08\n",
      "4   0.15  0.32  0.67  0.33  0.31  0.58  0.27  0.80  0.79  0.97\n",
      "5   0.67  0.77  0.02  0.86  0.99  0.52  0.39  0.34  0.57  0.99\n",
      "6   0.09  0.02  0.66  0.12  0.28  0.07  0.33  0.76  0.99  0.63\n",
      "7   0.07  0.16  0.07  0.24  0.00  0.67  0.04  0.95  0.28  0.37\n",
      "8   0.21  0.21  0.32  0.08  0.60  0.89  0.26  0.20  0.04  0.04\n",
      "9   0.38  0.03  0.71  0.88  0.15  0.51  0.79  0.43  0.02  0.65\n",
      "10  0.52  0.61  0.71  0.13  0.68  0.31  0.32  0.69  0.70  0.74\n",
      "11  0.37  0.60  0.58  0.94  0.19  0.69  0.40  0.83  0.47  0.57\n",
      "12  0.12  0.48  0.59  0.23  0.89  0.36  0.49  0.41  0.93  1.00\n",
      "13  0.30  0.53  0.43  0.41  0.35  0.30  0.93  0.14  0.70  0.11\n",
      "14  0.03  0.94  0.97  0.21  0.64  0.86  0.17  0.18  0.97  0.05\n",
      "15  0.17  0.46  0.87  0.53  0.96  0.76  0.77  0.88  0.83  0.38\n",
      "16  0.62  0.83  0.61  0.80  0.81  0.55  0.73  0.23  0.87  0.91\n",
      "17  0.96  0.96  0.23  0.50  0.40  0.96  0.42  0.78  0.52  0.59\n",
      "18  0.38  0.29  0.15  0.37  0.86  0.86  0.64  0.78  0.42  0.90\n",
      "19  0.96  0.34  0.33  0.49  0.40  0.92  0.13  0.48  0.24  0.14\n",
      "20  0.73  0.74  0.35  0.87  0.73  0.17  0.60  0.30  0.09  0.84\n",
      "21  0.66  0.20  0.31  0.64  0.01  0.15  0.35  0.80  0.58  0.89\n",
      "22  0.91  0.59  0.33  0.02  0.15  0.88  0.02  0.84  0.15  0.99\n",
      "23  0.95  0.72  0.72  0.72  0.16  0.37  0.82  0.32  0.43  0.17\n",
      "24  0.05  0.79  0.71  0.86  0.90  0.53  0.85  0.53  0.57  0.57\n",
      "25  0.35  0.77  0.15  0.71  0.42  0.87  0.28  0.01  0.93  0.93\n",
      "26  1.00  0.24  0.91  0.22  0.61  0.48  0.83  0.04  0.51  0.04\n",
      "27  0.03  0.92  0.43  0.07  0.14  0.36  0.84  0.22  0.45  0.76\n",
      "28  0.21  0.69  0.05  0.11  0.94  0.75  0.34  0.07  0.97  0.78\n",
      "29  0.70  0.02  0.81  0.45  0.93  0.13  0.44  0.20  0.76  0.41\n",
      "..   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...\n",
      "70  0.48  0.73  0.32  0.82  0.45  0.10  0.10  0.10  0.09  0.80\n",
      "71  0.14  0.05  0.97  0.84  0.56  0.62  0.83  0.89  0.61  0.04\n",
      "72  0.07  0.64  0.05  0.53  0.08  0.99  0.92  0.37  0.08  0.48\n",
      "73  0.58  0.18  0.98  0.86  0.37  0.16  0.79  1.00  0.34  0.10\n",
      "74  0.07  0.60  0.86  0.28  0.61  0.02  0.85  0.32  0.13  0.12\n",
      "75  0.07  0.25  0.49  0.30  0.34  0.74  0.62  0.79  0.34  0.07\n",
      "76  0.65  0.89  0.39  0.49  0.85  0.73  0.04  0.32  0.09  0.16\n",
      "77  0.19  0.51  0.43  0.94  0.71  0.03  0.60  0.68  0.59  0.53\n",
      "78  0.75  0.73  0.87  0.20  0.73  0.13  0.46  0.97  0.90  0.53\n",
      "79  0.17  0.10  0.49  0.44  0.88  0.20  0.58  0.67  0.96  0.26\n",
      "80  0.75  0.69  0.76  0.37  0.71  0.35  0.87  0.55  0.10  0.25\n",
      "81  0.96  0.89  0.68  0.42  0.51  0.55  0.93  0.03  0.33  0.81\n",
      "82  0.49  0.28  0.60  0.08  0.71  0.13  0.84  0.08  0.11  0.23\n",
      "83  0.35  0.49  0.89  0.67  0.58  0.84  0.76  0.72  0.21  0.19\n",
      "84  0.52  0.31  0.00  0.65  0.79  0.28  0.94  0.42  0.17  0.60\n",
      "85  0.96  0.18  0.72  0.82  0.22  0.23  0.59  0.90  0.98  0.33\n",
      "86  0.72  0.60  0.58  0.56  0.96  0.86  0.31  0.90  0.14  0.16\n",
      "87  0.70  0.21  0.49  0.65  0.14  0.11  1.00  0.56  0.92  0.43\n",
      "88  0.52  0.84  0.60  0.96  0.84  0.19  0.53  0.92  0.80  0.50\n",
      "89  0.66  0.14  0.98  0.66  0.73  0.09  0.41  0.87  0.13  0.97\n",
      "90  0.35  0.85  0.28  0.54  0.60  0.63  0.27  0.96  0.81  0.80\n",
      "91  0.94  0.65  0.92  0.72  0.38  0.06  0.77  0.05  0.28  0.33\n",
      "92  0.41  0.59  0.88  0.04  0.77  0.73  0.26  0.99  0.99  0.92\n",
      "93  0.66  0.78  0.41  0.56  0.02  0.54  0.15  0.82  0.03  0.33\n",
      "94  0.25  0.32  0.34  0.91  0.23  0.79  1.00  0.45  0.53  0.05\n",
      "95  0.82  0.73  0.07  0.98  0.31  0.39  0.48  0.03  0.69  0.86\n",
      "96  0.31  0.73  0.54  0.20  0.64  0.36  0.74  0.69  0.81  0.96\n",
      "97  0.86  0.44  0.96  0.72  0.67  0.22  0.16  0.18  0.09  0.89\n",
      "98  0.41  0.93  0.68  0.69  0.34  0.63  0.18  0.87  0.11  0.12\n",
      "99  0.48  0.00  0.07  0.86  0.79  0.89  0.34  0.88  0.40  0.61\n",
      "\n",
      "[100 rows x 10 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "*********************************\n",
      "          C_E   C_I  C_ID   C_C   C_T   C_R   C_A   C_P  C_ETB\n",
      "C_1_1    0.45  0.72  0.31  0.05  0.91  0.75  0.06  0.88   0.97\n",
      "C_1_2    0.12  0.26  0.04  0.73  0.61  0.30  0.43  0.13   0.35\n",
      "C_1_3    0.47  0.64  0.22  0.07  0.16  0.75  0.52  0.65   0.53\n",
      "C_1_4    0.70  0.70  0.78  0.81  0.62  0.61  0.32  0.69   1.00\n",
      "C_1_5    0.11  0.17  0.90  0.06  0.77  0.55  0.73  0.25   0.71\n",
      "C_1_6    0.42  0.23  0.69  0.34  0.00  0.71  0.73  0.08   0.59\n",
      "C_1_7    0.36  0.99  0.84  0.97  0.34  0.49  0.56  0.27   0.67\n",
      "C_1_8    0.78  0.26  0.07  0.71  0.43  0.52  0.71  0.26   0.38\n",
      "C_1_9    0.86  0.13  0.62  0.80  0.44  0.42  0.22  0.14   0.10\n",
      "C_1_10   0.88  0.61  0.46  0.69  0.21  0.23  0.30  0.36   0.02\n",
      "C_1_11   0.11  0.44  0.19  0.51  0.55  0.62  0.79  0.86   0.60\n",
      "C_1_12   0.92  1.00  0.51  0.08  0.57  0.42  0.40  0.65   0.26\n",
      "C_1_13   0.40  0.40  0.20  0.54  0.42  0.24  0.51  0.88   0.98\n",
      "C_1_14   0.79  0.37  0.60  0.79  0.36  0.77  0.94  0.69   0.77\n",
      "C_2_1    0.14  0.70  0.29  0.74  1.00  0.54  0.40  0.88   0.65\n",
      "C_2_2    0.44  0.22  0.84  0.52  0.35  0.38  0.32  0.57   0.63\n",
      "C_2_3    0.95  0.02  0.29  0.70  0.18  0.49  0.79  0.48   0.05\n",
      "C_2_4    0.65  0.35  0.72  0.88  0.14  0.89  0.96  0.17   0.17\n",
      "C_2_5    0.93  0.74  0.56  0.22  0.70  0.91  0.33  0.80   0.70\n",
      "C_2_6    0.02  0.11  0.10  0.08  0.71  0.18  0.23  0.74   0.44\n",
      "C_2_7    0.47  0.03  0.32  0.23  0.37  0.34  0.06  0.27   0.54\n",
      "C_2_8    0.68  0.20  0.78  0.72  0.20  0.58  0.96  0.10   0.69\n",
      "C_3_1    0.24  0.70  0.55  0.46  0.87  0.10  0.38  0.71   0.34\n",
      "C_3_2    0.44  0.80  0.65  0.48  0.08  0.79  0.36  0.22   0.54\n",
      "C_3_3    0.23  0.98  0.98  0.73  0.66  0.42  0.80  0.52   0.32\n",
      "C_3_4    0.18  0.85  0.64  0.06  0.74  0.12  0.24  0.68   0.46\n",
      "C_3_5    0.67  0.21  0.59  0.62  0.28  0.16  0.62  0.72   0.08\n",
      "C_3_6    0.67  0.73  0.08  0.38  0.46  0.49  0.64  0.71   0.26\n",
      "C_3_7    0.81  0.79  0.07  0.56  0.11  0.94  0.89  0.38   0.38\n",
      "C_3_8    0.72  0.15  0.65  0.24  0.51  0.73  0.62  0.20   0.75\n",
      "...       ...   ...   ...   ...   ...   ...   ...   ...    ...\n",
      "C_23_10  0.34  0.72  0.92  0.42  0.15  0.86  0.32  0.64   0.98\n",
      "C_23_11  0.59  0.45  0.15  0.37  0.86  0.78  0.03  0.17   0.74\n",
      "C_23_12  0.68  0.87  0.69  0.95  0.77  0.46  0.69  0.89   0.61\n",
      "C_23_13  0.54  0.61  0.22  0.52  0.24  0.89  0.22  0.95   0.83\n",
      "C_23_14  0.30  0.93  0.77  0.31  0.49  0.30  0.57  0.28   0.96\n",
      "C_23_15  0.51  0.74  0.23  0.19  0.38  0.52  0.94  0.39   0.79\n",
      "C_23_16  0.75  0.35  0.39  0.73  0.40  0.57  0.29  0.39   0.77\n",
      "C_24_1   0.21  0.76  0.11  0.86  0.93  0.90  0.54  0.17   0.48\n",
      "C_24_2   0.88  0.42  0.41  0.89  0.05  0.28  0.46  0.75   0.69\n",
      "C_24_3   0.76  0.24  0.99  0.90  0.86  0.48  0.60  0.62   0.61\n",
      "C_24_4   0.08  0.88  0.42  0.42  0.42  0.33  0.52  0.83   0.27\n",
      "C_24_5   0.91  0.74  0.29  0.16  0.93  0.02  0.12  0.44   0.17\n",
      "C_24_6   0.53  0.35  0.85  0.38  0.76  0.50  0.72  0.82   0.58\n",
      "C_24_7   0.40  0.16  0.98  0.10  0.47  0.37  0.82  0.80   0.69\n",
      "C_24_8   0.05  0.21  0.54  0.57  0.64  0.46  0.13  0.15   0.93\n",
      "C_24_9   0.49  0.30  0.35  0.66  0.31  0.74  0.08  0.31   0.53\n",
      "C_25_1   0.22  0.21  0.96  0.90  0.85  0.28  0.74  0.23   0.56\n",
      "C_25_2   0.53  0.58  0.13  0.34  0.57  0.93  0.88  0.67   0.91\n",
      "C_25_3   0.38  0.21  0.64  0.75  0.86  0.74  0.08  0.05   0.51\n",
      "C_25_4   0.61  0.35  0.86  0.44  0.46  0.90  0.68  0.65   0.58\n",
      "C_25_5   0.99  0.26  0.81  0.52  0.60  0.30  0.91  0.42   0.42\n",
      "C_25_6   0.73  0.98  0.78  0.06  0.75  0.99  0.21  0.47   0.07\n",
      "C_25_7   0.79  0.95  0.56  0.40  0.57  0.01  0.26  0.86   0.38\n",
      "C_25_8   0.96  0.28  0.08  0.06  0.52  0.96  0.77  0.50   0.86\n",
      "C_25_9   0.41  0.20  0.52  0.17  0.86  0.10  0.26  0.58   0.77\n",
      "C_25_10  0.36  0.06  0.59  0.06  0.21  0.27  0.88  0.53   0.59\n",
      "C_25_11  0.63  0.02  0.56  0.66  0.75  0.76  0.10  0.96   0.27\n",
      "C_25_12  0.79  0.08  0.83  0.46  0.25  0.89  0.13  0.86   0.27\n",
      "C_25_13  0.29  0.06  0.90  0.36  0.64  0.38  0.53  0.92   0.19\n",
      "C_25_14  0.94  0.37  0.58  0.21  0.67  0.09  0.87  0.36   0.04\n",
      "\n",
      "[329 rows x 9 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "*********************************\n",
      "['T_1', 'T_2', 'T_3', 'T_4', 'T_5', 'T_6', 'T_7', 'T_8', 'T_9', 'T_10', 'T_11', 'T_12', 'T_13', 'T_14', 'T_15', 'T_16', 'T_17', 'T_18', 'T_19', 'T_20', 'T_21', 'T_22', 'T_23', 'T_24', 'T_25']\n",
      "<class 'list'>\n",
      "*********************************\n",
      "{'T_11': ['C_11_1', 'C_11_2', 'C_11_3', 'C_11_4', 'C_11_5', 'C_11_6', 'C_11_7', 'C_11_8'], 'T_10': ['C_10_1', 'C_10_2', 'C_10_3', 'C_10_4', 'C_10_5', 'C_10_6', 'C_10_7', 'C_10_8', 'C_10_9', 'C_10_10', 'C_10_11', 'C_10_12', 'C_10_13', 'C_10_14'], 'T_2': ['C_2_1', 'C_2_2', 'C_2_3', 'C_2_4', 'C_2_5', 'C_2_6', 'C_2_7', 'C_2_8'], 'T_17': ['C_17_1', 'C_17_2', 'C_17_3', 'C_17_4', 'C_17_5', 'C_17_6', 'C_17_7', 'C_17_8', 'C_17_9', 'C_17_10', 'C_17_11', 'C_17_12', 'C_17_13', 'C_17_14', 'C_17_15', 'C_17_16', 'C_17_17', 'C_17_18'], 'T_23': ['C_23_1', 'C_23_2', 'C_23_3', 'C_23_4', 'C_23_5', 'C_23_6', 'C_23_7', 'C_23_8', 'C_23_9', 'C_23_10', 'C_23_11', 'C_23_12', 'C_23_13', 'C_23_14', 'C_23_15', 'C_23_16'], 'T_20': ['C_20_1', 'C_20_2', 'C_20_3', 'C_20_4', 'C_20_5', 'C_20_6', 'C_20_7', 'C_20_8', 'C_20_9', 'C_20_10'], 'T_22': ['C_22_1', 'C_22_2', 'C_22_3', 'C_22_4', 'C_22_5', 'C_22_6', 'C_22_7', 'C_22_8'], 'T_6': ['C_6_1', 'C_6_2', 'C_6_3', 'C_6_4', 'C_6_5', 'C_6_6', 'C_6_7', 'C_6_8'], 'T_3': ['C_3_1', 'C_3_2', 'C_3_3', 'C_3_4', 'C_3_5', 'C_3_6', 'C_3_7', 'C_3_8', 'C_3_9', 'C_3_10', 'C_3_11', 'C_3_12', 'C_3_13', 'C_3_14', 'C_3_15', 'C_3_16', 'C_3_17'], 'T_15': ['C_15_1', 'C_15_2', 'C_15_3', 'C_15_4', 'C_15_5', 'C_15_6', 'C_15_7', 'C_15_8', 'C_15_9', 'C_15_10', 'C_15_11', 'C_15_12', 'C_15_13', 'C_15_14', 'C_15_15', 'C_15_16', 'C_15_17', 'C_15_18', 'C_15_19', 'C_15_20'], 'T_9': ['C_9_1', 'C_9_2', 'C_9_3', 'C_9_4', 'C_9_5', 'C_9_6', 'C_9_7', 'C_9_8', 'C_9_9'], 'T_19': ['C_19_1', 'C_19_2', 'C_19_3', 'C_19_4', 'C_19_5', 'C_19_6', 'C_19_7', 'C_19_8', 'C_19_9', 'C_19_10', 'C_19_11', 'C_19_12', 'C_19_13'], 'T_8': ['C_8_1', 'C_8_2', 'C_8_3', 'C_8_4', 'C_8_5', 'C_8_6', 'C_8_7', 'C_8_8', 'C_8_9', 'C_8_10', 'C_8_11', 'C_8_12', 'C_8_13', 'C_8_14', 'C_8_15', 'C_8_16', 'C_8_17', 'C_8_18', 'C_8_19', 'C_8_20'], 'T_24': ['C_24_1', 'C_24_2', 'C_24_3', 'C_24_4', 'C_24_5', 'C_24_6', 'C_24_7', 'C_24_8', 'C_24_9'], 'T_12': ['C_12_1', 'C_12_2', 'C_12_3', 'C_12_4', 'C_12_5', 'C_12_6'], 'T_16': ['C_16_1', 'C_16_2', 'C_16_3', 'C_16_4', 'C_16_5', 'C_16_6', 'C_16_7', 'C_16_8', 'C_16_9', 'C_16_10', 'C_16_11', 'C_16_12', 'C_16_13', 'C_16_14', 'C_16_15'], 'T_7': ['C_7_1', 'C_7_2', 'C_7_3', 'C_7_4', 'C_7_5', 'C_7_6', 'C_7_7', 'C_7_8', 'C_7_9', 'C_7_10', 'C_7_11', 'C_7_12', 'C_7_13', 'C_7_14', 'C_7_15', 'C_7_16', 'C_7_17', 'C_7_18', 'C_7_19'], 'T_18': ['C_18_1', 'C_18_2', 'C_18_3', 'C_18_4', 'C_18_5', 'C_18_6'], 'T_5': ['C_5_1', 'C_5_2', 'C_5_3', 'C_5_4', 'C_5_5', 'C_5_6', 'C_5_7', 'C_5_8', 'C_5_9', 'C_5_10', 'C_5_11', 'C_5_12', 'C_5_13', 'C_5_14', 'C_5_15', 'C_5_16', 'C_5_17', 'C_5_18', 'C_5_19', 'C_5_20'], 'T_13': ['C_13_1', 'C_13_2', 'C_13_3', 'C_13_4', 'C_13_5', 'C_13_6', 'C_13_7', 'C_13_8', 'C_13_9', 'C_13_10', 'C_13_11', 'C_13_12', 'C_13_13', 'C_13_14', 'C_13_15', 'C_13_16', 'C_13_17', 'C_13_18'], 'T_21': ['C_21_1', 'C_21_2', 'C_21_3', 'C_21_4', 'C_21_5', 'C_21_6', 'C_21_7', 'C_21_8', 'C_21_9', 'C_21_10', 'C_21_11', 'C_21_12'], 'T_4': ['C_4_1', 'C_4_2', 'C_4_3', 'C_4_4', 'C_4_5', 'C_4_6', 'C_4_7', 'C_4_8', 'C_4_9', 'C_4_10', 'C_4_11', 'C_4_12', 'C_4_13', 'C_4_14', 'C_4_15', 'C_4_16', 'C_4_17', 'C_4_18'], 'T_25': ['C_25_1', 'C_25_2', 'C_25_3', 'C_25_4', 'C_25_5', 'C_25_6', 'C_25_7', 'C_25_8', 'C_25_9', 'C_25_10', 'C_25_11', 'C_25_12', 'C_25_13', 'C_25_14'], 'T_14': ['C_14_1', 'C_14_2', 'C_14_3', 'C_14_4', 'C_14_5', 'C_14_6', 'C_14_7', 'C_14_8', 'C_14_9'], 'T_1': ['C_1_1', 'C_1_2', 'C_1_3', 'C_1_4', 'C_1_5', 'C_1_6', 'C_1_7', 'C_1_8', 'C_1_9', 'C_1_10', 'C_1_11', 'C_1_12', 'C_1_13', 'C_1_14']}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "import os,pickle\n",
    "\n",
    "# file_path = os.path.join(os.path.curdir, '..' , 'dataset' , 'very_small')\n",
    "file_path = os.path.join(os.path.curdir, '..' , 'dataset' , 'small')\n",
    "# file_path = os.path.join(os.path.curdir, '..' , 'dataset' , 'medium')\n",
    "# file_path = os.path.join(os.path.curdir, '..' , 'dataset' , 'large')\n",
    "# file_path = os.path.join(os.path.curdir, '..' , 'dataset' , 'very_large')\n",
    "'''\n",
    "Context data for learning\n",
    "'''\n",
    "class Context:\n",
    "    \"\"\"\n",
    "    Contextual information required by contextual bandit algorithms to make better predictions. It enscapsulates all data\n",
    "    about the student , topics & content to experiment with the oracle\n",
    "    \"\"\"\n",
    "   \n",
    "    def getStudentContext(self):\n",
    "        \"\"\"\n",
    "        Student Preferences: \n",
    "        Visual (S_V) , Text (S_T) , Demo-based (S_D) , Practical (S_P), Step-by-step (S_S) ,Activity / Task based (S_AT), \n",
    "        Lecture (S_L) , Audio (S_A) , Self-evaluation (S_SE) , Pre-assessment (S_PA)\n",
    "        Students preference to learning via various ways are evaluated on a scale from 0 to 1, rather being binary. \n",
    "        \"\"\"\n",
    "        return self.studentContext\n",
    "    \n",
    "    def setStudentContext(self):\n",
    "        \"\"\"\n",
    "        Load the student data\n",
    "        \"\"\"\n",
    "        with open(os.path.join(file_path , 'student.pickle'), 'rb') as student_file:\n",
    "            self.studentContext= pickle.load(student_file)\n",
    "    \n",
    "    def getContentContext(self):\n",
    "        \"\"\"\n",
    "        Content Features \n",
    "        Ease of understanding (C_E) , Simple / Intuitive (C_I) , Surface / In-depth (C_ID) , Brief / Concise (C_C), \n",
    "        Thorough (C_T), Preference / Well reviewed / Well rated (C_R) , Theoritical / Abstract (C_A), \n",
    "        Practical / Hands on (C_P), Experimental / Task-based (C_ETB)\n",
    "        Content preference to learning via various ways are evaluated on a scale from 0 to 1, rather being binary. \n",
    "        \"\"\"\n",
    "        return self.contentContext\n",
    "   \n",
    "    def setContentContext(self):\n",
    "        \"\"\"\n",
    "        Load the content data\n",
    "        \"\"\"\n",
    "        with open(os.path.join(file_path ,'content.pickle'), 'rb') as content_file:\n",
    "            self.contentContext= pickle.load(content_file)\n",
    "        \n",
    "    def getTopic(self):\n",
    "        \"\"\"\n",
    "        Gives the topics part of the course.\n",
    "        \"\"\"\n",
    "        return self.topic\n",
    "    \n",
    "    def setTopic(self):\n",
    "        \"\"\"\n",
    "        Loads the topics part of the course\n",
    "        \"\"\"\n",
    "        with open(os.path.join(file_path ,'topic.pickle'), 'rb') as topic_file:\n",
    "            self.topic = pickle.load(topic_file)\n",
    "    \n",
    "    def getTopicContent(self):\n",
    "        \"\"\"\n",
    "         Gets the topic content. topic_content is a map of topics to content. So for every topic, it gives the content \n",
    "         available for the topic. In education parlance, for any given topic, it shows the different ways of teaching this\n",
    "         topic (via contents)\n",
    "        \"\"\"\n",
    "        return self.topic_content\n",
    "    \n",
    "    def setTopicContent(self):\n",
    "        \"\"\"\n",
    "        Sets the topic_content variable to the one in the serialized object. topic_content is a map of topics to content. So\n",
    "        for every topic, it gives the content available for the topic. In education parlance, for any given topic, it shows\n",
    "        the different ways of teaching this topic (via contents)\n",
    "        \"\"\"\n",
    "        with open(os.path.join(file_path ,'topic_content.pickle'), 'rb') as topic_content_file:\n",
    "            self.topic_content= pickle.load(topic_content_file)\n",
    "                \n",
    "    def prepareContext(self,studentContext,contentContext):\n",
    "        \"\"\"\n",
    "           Given the student & content context available for a round, this method combines them to form a single contextual\n",
    "           variable\n",
    "           \n",
    "           Inputs : \n",
    "           \n",
    "           studentContext: Student contextual information.\n",
    "           contentContext: Contents contextual information. \n",
    "           \n",
    "           Returns :\n",
    "           \n",
    "           context : A combined output of student & content context.\n",
    "        \"\"\"\n",
    "        context = pd.DataFrame() \n",
    "        for content in list(contentContext.index):\n",
    "            c = pd.Series()\n",
    "            c = c.append([studentContext,contentContext.loc[content]]) # Combine student & content. \n",
    "            c['Content_id'] = content\n",
    "            context = context.append(c, ignore_index=True)\n",
    "        context = context.set_index('Content_id')\n",
    "        return context\n",
    "    \n",
    "    def loadData(self):\n",
    "        \"\"\"\n",
    "        Method used to test data retrieval. Data generator handles the data generation. This method checks we can retrieve\n",
    "        data. This is a dummy method used to test data retrieval. Its not invoked in the main program.\n",
    "        \"\"\"\n",
    "        self.setStudentContext()\n",
    "        self.setContentContext()\n",
    "        self.setTopic()\n",
    "        self.setTopicContent()\n",
    "        print(\"Student Context Shape : \", self.getStudentContext().shape)\n",
    "        print(\"Content Context Shape : \", self.getContentContext().shape)\n",
    "        print(\"**********************************\")\n",
    "        print(self.getStudentContext())\n",
    "        print(type(self.getStudentContext()))\n",
    "        print('*********************************')\n",
    "        print(self.getContentContext())\n",
    "        print(type(self.getContentContext()))\n",
    "        print('*********************************')\n",
    "        print(self.getTopic())\n",
    "        print(type(self.getTopic()))\n",
    "        print('*********************************')\n",
    "        print(self.getTopicContent())\n",
    "        print(type(self.getTopicContent()))\n",
    "                \n",
    "c_test = Context()\n",
    "c_test.loadData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skip Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online Stochastic Gradient Descent. This classifier decides whether or not to skip to the next topic. \n",
    "# TO-DO : Change loss functions (Log,Hinge,Others) to find if they impact performance. Try different values of parameters \n",
    "# For instance SGD has a parameter alpha, SVM has a parameter C. To optimize, you can train a mini-batch of samples, \n",
    "# rather than one data point at a time. Try different values of learning_rate . Look at the class_weight parameter if you \n",
    "# want to give more weight to samples of one class over the other. Need to understand about warm_start parameter\n",
    "# We need to record predictions made by the classifier to evaluate its performance over rounds.\n",
    "from sklearn import linear_model\n",
    "class SkipClassifier:\n",
    "    \"\"\"\n",
    "    A classifier which gives prediction, whether or not to move to the next topic. This is important, because we want \n",
    "    students to learn content which the algorithm is confident would help the student learn. The skip classifier is trained\n",
    "    online, hence we use a confidence threshold, to be conservative & minimize skipping topics. Skipping is not preferred, \n",
    "    but if the classifier is confident the next round would help gain higher rewards, then we should skip. Ideally, we want \n",
    "    to consider skipping after the first pulled arm has failed, to avoid frustrating the student. \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.clf = linear_model.SGDClassifier()\n",
    "        self.clf.partial_fit(np.array([[0,0,0,0,0,0,0,0,0,0,0,0]]),np.array([0]),classes=np.array([0,1])) # Used to initialize the skip classifier\n",
    "        \n",
    "    def check_fitted(self,clf): \n",
    "        \"\"\"\n",
    "        Check if the classifier is fit before asking for prediction. Our classifier is trained in online mode, hence it would\n",
    "        be asked to predict before fitting. This method makes sure we only ask for prediction after a data point has been \n",
    "        fit to the estimator/model\n",
    "        \"\"\"\n",
    "        return hasattr(clf, \"classes_\")\n",
    "    \n",
    "    def train(self,student,pta,next_topic_pta,label):\n",
    "        \"\"\"\n",
    "        Used to train the classifier in online mode, over every data point. In future we might want to consider training in \n",
    "        mini-batches, rather than for every data point. \n",
    "        \"\"\"\n",
    "        X = pd.Series()\n",
    "        X = X.append([student,pd.Series([pta,next_topic_pta],index=['pta','next_topic_pta'])])\n",
    "        X = np.array([X.values])\n",
    "        Y = np.array([label])\n",
    "        self.clf = self.clf.partial_fit(X,Y)\n",
    "               \n",
    "    def predict(self,student,pta,next_topic_pta):\n",
    "        \"\"\"\n",
    "        Gets predictions from the classifier, along with the confidence score to help determine the reliability / confidence\n",
    "        level of the prediction being made. \n",
    "        \"\"\"\n",
    "        X = pd.Series()\n",
    "        X = X.append([student,pd.Series([pta,next_topic_pta],index=['pta','next_topic_pta'])])\n",
    "        if self.check_fitted(self.clf):\n",
    "            Y = self.clf.predict([X.values])[0]\n",
    "            confidence_score = self.clf.decision_function([X.values])[0]\n",
    "        else:\n",
    "            Y = 0\n",
    "            confidence_score = 0\n",
    "        return int(Y) , confidence_score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SkipTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipTopic:\n",
    "    \"\"\"\n",
    "    A wrapper around the Skip Classifier to validate the inputs, before sending it to Skip Classifier for prediction. \n",
    "    It post-processes the results of the prediction made by skip classifier to check for confidence threshold, \n",
    "    before sending out the decision to skip or not. \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the SkipTopic class & sets confidence threshold to make confident skip decisions.\n",
    "        \"\"\"\n",
    "        self.skipClassifier = SkipClassifier()\n",
    "        self.confidence_threshold = 100 # It the confidence score returned by the classifier is greater than this, then we trust in the decision made by the classifier. \n",
    "                \n",
    "    def skipTopic(self,student,pta,topic_number,context_obj,topic_content,oracle):\n",
    "        \"\"\"\n",
    "        Pre-validates the topic number before asking the skip classifier for a prediction. Then checks the confidence \n",
    "        of the prediction before sending out the decision to skip or not. \n",
    "        \"\"\"\n",
    "        contentContext = context_obj.getContentContext() # Get the content dataframe.\n",
    "        topic = context_obj.getTopic() # Get the topic list. \n",
    "        current_topic_index = topic.index(topic_number) # Get the index number of the current topic\n",
    "        next_topic_index = current_topic_index + 1\n",
    "        next_topic = '' # Initialized to make it accessible outside the if statement. \n",
    "        if next_topic_index < len(topic): # Check to see if we're going out of bounds\n",
    "            next_topic = topic[next_topic_index]\n",
    "            next_topic_contents = topic_content[next_topic]\n",
    "            t_c = contentContext.loc[next_topic_contents]\n",
    "            X = context_obj.prepareContext(student,t_c)\n",
    "            arm_pulled , next_topic_pta = oracle.expectedPayoff(X,next_topic_contents)\n",
    "        else:\n",
    "            # Will be going out of bounds. Current topic is the last topic. No more topics to complete. \n",
    "            next_topic_pta = 0\n",
    "        actual_decision , confidence_score = self.skipClassifier.predict(student,pta,next_topic_pta)\n",
    "        if actual_decision and confidence_score > self.confidence_threshold:\n",
    "            skip_decision = 1\n",
    "        else:\n",
    "            skip_decision = 0\n",
    "        return actual_decision,confidence_score,skip_decision,next_topic_pta\n",
    "\n",
    "    def setLabel(self,actual_payoff):\n",
    "        \"\"\"\n",
    "        Sets the label for training the skip classifier\n",
    "        \"\"\"\n",
    "        if actual_payoff == 0:\n",
    "            label = 1\n",
    "        if actual_payoff == 1:\n",
    "            label = 0\n",
    "        return label\n",
    "    \n",
    "    def train(self,student,pta,pta_next_topic,label):\n",
    "        \"\"\"\n",
    "        Training the skip classifier\n",
    "        \"\"\"\n",
    "        self.skipClassifier.train(student,pta,pta_next_topic,label)              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Omniscient Policy / Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Oracle :\n",
    "    \"\"\"\n",
    "    It has the optimal parameters to maximize rewards. The learning algorithm updates its parameters to emulate its parameters\n",
    "    It is an omniscient policy that knows all of the probability distributions. This is the algorithm which, every step of \n",
    "    the way, makes the best decision based on its knowledge of the true distributions (it does not have to learn anything). \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initalizes parameters for the omniscient policy. \n",
    "        \"\"\"\n",
    "        self.rounds = 0 # Number of round played\n",
    "        self.rounds_data = pd.DataFrame() # Rounds data required for Skip Algorithm\n",
    "        self.skipTopic = SkipTopic()\n",
    "    \n",
    "    def setParameters(self, features , arms): # Setting optimal parameter theta\n",
    "        \"\"\"\n",
    "        Sets the optimal parameters for the omniscient policy. \n",
    "        \"\"\"\n",
    "        parameters = np.random.uniform(size=(len(arms) , len(features)))\n",
    "        # Normalize parameters\n",
    "        for i in range(parameters.shape[0]): # Have it in a list comprehension.\n",
    "            parameters[i] = parameters[i] / np.sum(parameters[i])\n",
    "        self.theta_df = pd.DataFrame(data = parameters ,  index = arms , columns = features , dtype= np.float)\n",
    "    \n",
    "    def expectedPayoff(self,contexts,arms):\n",
    "        \"\"\"\n",
    "        Gives the max expected pay-off for a round with the given context & available arms. The arm is not pulled up here as we \n",
    "        also depend of the decision from the skip classifer before the arm is actually pulled.         \n",
    "        \n",
    "        Input : \n",
    "        \n",
    "        contexts : Contextual data available in the round. Its a combination of student & content context\n",
    "        arms : Arms / Content available in this round. \n",
    "        \n",
    "        Returns : \n",
    "        \n",
    "        arm_pulled : The arm that should be pulled \n",
    "        expected_payoff : Expected pay-off for the pulled suggested to be pulled. \n",
    "        \n",
    "        \"\"\"\n",
    "        arms_payoff = list()\n",
    "        for arm in arms:\n",
    "            arm_theta = self.theta_df.loc[arm]\n",
    "            X = contexts.loc[arm]\n",
    "            pta = pd.Series.dot(X,arm_theta) # Vector dim : (1 * d) (d * 1).\n",
    "            arms_payoff.append(pta)\n",
    "        arm_index = np.argmax(arms_payoff)\n",
    "        arm_pulled = arms[arm_index]\n",
    "        expected_payoff = np.max(arms_payoff)\n",
    "        return arm_pulled,np.round(expected_payoff,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "class Simulator:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.context = Context()\n",
    "        self.context.setStudentContext()\n",
    "        self.context.setContentContext()\n",
    "        self.context.setTopic()\n",
    "        self.context.setTopicContent()\n",
    "        self.oracle = Oracle()\n",
    "        self.skipTopic = SkipTopic()\n",
    "        self.simulator_lock = threading.Lock()\n",
    "        self.rounds=0\n",
    "        self.logs = pd.DataFrame(columns = ['student_number','topic','arm_pulled','pay-off','pay-off_next_topic','actual_decision','skip_decision'\n",
    "                                            ,'reward']) \n",
    "\n",
    "    def getPayoff(self,pta):\n",
    "        \"\"\"\n",
    "        Student shares feedback about the content / understanding of the topic. \n",
    "        \n",
    "        Input : \n",
    "        \n",
    "        pta : Payoff at round 't' for pulling an arm. \n",
    "        \n",
    "        Returns : \n",
    "        \n",
    "        reward : Reward / Feedback from student for the content shown / arm pulled\n",
    "        \"\"\"\n",
    "        reward = bernoulli.rvs(size=1,p=pta)[0] # Simulate student's response\n",
    "        return reward\n",
    "    \n",
    "    def takeCourse(self,student_number,studentContext,contentContext,topic,topic_content):\n",
    "        \"\"\"\n",
    "        This method simulates students taking a course. As part of it, students are presented content for various topics. \n",
    "        Students share their feedback, based on which we either move to the next topic or remain on the same topic.  \n",
    "        We get the expected pay-off from the oracle. We then decide whether to skip or remain on the same topic.\n",
    "        If skip is true, then the student moves to the next topic, else the student remains on the same topic, shares feedback on \n",
    "        the content & we train the skip classifier with this feedback. This method drives the flow of the system, hence key \n",
    "        data elements available in this method are logged for analysis.\n",
    "        \n",
    "        Inputs : \n",
    "        \n",
    "        student_number : Student Id \n",
    "        studentContext : Student context vector. \n",
    "        contentContext : Contents context. This has context of all contents for the topic. \n",
    "        topic : All the topics to be taught as part of the course. \n",
    "        topic_content : Relates all topics to the contents available for every topic     \n",
    "         \n",
    "        \"\"\"\n",
    "        for i in topic:\n",
    "            skip_enabled = False # Done to disable skipping without attempting to teach a student. \n",
    "            contents = topic_content[i] # You now have all arm associated with the topic 't'\n",
    "            t_c = contentContext.loc[contents]\n",
    "            contexts = self.context.prepareContext(studentContext,t_c)\n",
    "            arms = list(t_c.index)\n",
    "            while arms:\n",
    "                arm , pta = self.oracle.expectedPayoff(contexts,arms)\n",
    "                actual_decision , confidence_score, skip_decision , pta_next_topic = self.skipTopic.skipTopic(studentContext,pta,i,self.context,topic_content,self.oracle)\n",
    "                if skip_decision and skip_enabled:\n",
    "                    log = pd.Series([student_number,i,arm,pta,pta_next_topic,actual_decision,confidence_score,skip_decision], \n",
    "                                        index=['student_number','topic','arm_pulled','pay-off',\n",
    "                                                'pay-off_next_topic','actual_decision','confidence_score','skip_decision']) # Print log for this round\n",
    "                    with self.simulator_lock:\n",
    "                        print('We\\'re skipping. Student {0} is on topic {1} was expected to be shown content {2}. Expected Pay-off of this arm is {3}, compared to expected pay-off of next round is {4}. Actual decision was {5} with confidence {6} Decision of skip classifier is {7}'\n",
    "                          .format(student_number,i,arm,pta,pta_next_topic,actual_decision,confidence_score,skip_decision))                    \n",
    "                        self.logs = self.logs.append(log , ignore_index=True) # Log in a file\n",
    "                    break # Decision is to skip. Hence, we won't pull the arm. \n",
    "                else:\n",
    "                    actual_payoff = self.getPayoff(pta)\n",
    "                    log = pd.Series([student_number,i,arm,pta,pta_next_topic,actual_decision,confidence_score,skip_decision,actual_payoff], \n",
    "                                        index=['student_number','topic','arm_pulled','pay-off',\n",
    "                                                'pay-off_next_topic','actual_decision','confidence_score','skip_decision','reward']) # Print log for this round\n",
    "                    with self.simulator_lock:\n",
    "                        self.rounds+=1\n",
    "                        print('Student {0} is on topic {1} is shown content {2} feedback recd is {3}. Expected Pay-off of this arm is {4}, compared to expected pay-off of next round is {5}. Actual decision was {6} with confidence {7}. Decision of skip classifier is {8}'\n",
    "                              .format(student_number,i,arm,actual_payoff,pta,pta_next_topic,actual_decision,confidence_score,skip_decision))\n",
    "                        self.logs = self.logs.append(log , ignore_index=True) # Log in a file\n",
    "                    label = self.skipTopic.setLabel(actual_payoff) # Set Label\n",
    "                    self.skipTopic.train(studentContext,pta,pta_next_topic,label)\n",
    "                if actual_payoff != 1:\n",
    "                    arms.remove(arm)\n",
    "                    skip_enabled = True\n",
    "                else:\n",
    "                    break # Move to the next topic \n",
    "\n",
    "    def main(self):\n",
    "        \"\"\"\n",
    "        Its the main method. Its in the name :)\n",
    "        \"\"\"\n",
    "        studentContext = self.context.getStudentContext() # Student dataframe\n",
    "        contentContext = self.context.getContentContext() # Content Dataframe\n",
    "        topic = self.context.getTopic() # List of topics. \n",
    "        topic_content = self.context.getTopicContent() # Topics Data, which includes topics to content mapping.\n",
    "        features = list(studentContext.columns) + list(contentContext.columns)\n",
    "        self.oracle.setParameters(features , contentContext.index) \n",
    "        student_thread = list() # Keep track of students taking the course. \n",
    "        for student_number , student in studentContext.iterrows():\n",
    "            t = threading.Thread(target=self.takeCourse, args=(student_number,student,contentContext,topic,topic_content))\n",
    "            student_thread.append(t)\n",
    "            # Some threads do background tasks, like sending keepalive packets, or performing periodic garbage collection, or \n",
    "            # whatever. These are only useful when the main program is running, and it's okay to kill them off once the other, \n",
    "            # non-daemon, threads have exited. Once the main thread finishes & one of the student is still working through the course. \n",
    "            # we will wait for the student to complete the course, since the main thread is completed. We want all students \n",
    "            # to complete the course. Hence, setting daemon to False\n",
    "            t.daemon = False # classifying as a daemon, so they will die when the main dies\n",
    "            t.start() # begins, must come after daemon definition\n",
    "        for t in student_thread: # This is done to ensure, we proceed to save the logs only after all students have completed the course. \n",
    "            t.join()\n",
    "        self.logs.to_csv('logs_oracle_small_NoSkipping',index=False)\n",
    "        print('Total Number of rounds : ', self.rounds)  \n",
    "    \n",
    "simulator = Simulator()\n",
    "simulator.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('logs_oracle_small')\n",
    "#df[df['confidence_score'] > 25]\n",
    "df[df['student_number'] == 8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
