{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset \n",
    "\n",
    "This notebook creates a dataset used for all our experiments. Using a common dataset helps in robust evaluation of our learning algorithm, with respect to the omniscient policy. \n",
    "\n",
    "We create a dataset & save it for use by the learning algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Features \n",
    "\n",
    "Research has shown that students prefer to learn a certain way. Though there is no unanimous choice, there is a fair bit of understanding of what a student wants from the content they are trying to understand. We'll assume, there was a survey conducted among students, which asked to know how should information be taught to help them understand in a streamlined manner. \n",
    "\n",
    "1. Visual (V): How much preference is given to visual explanations (video, short-film, movie-clip, vlogs).\n",
    "2. Text (T): How much preference is given to written explanations (books, articles, blogs, research papers)\n",
    "3. Demo-based (D): Preference to live experimentation to help understand the concept.\n",
    "4. Practical (P): Explain or demo the topic, & enable us to perform it.\n",
    "5. Step-by-step (S): A guide to practicing / trying to understand the topic in a systematic way.\n",
    "6. Activity / Task based (AT): Preference to contents that are interactive \\& require students to participate\n",
    "7. Lecture (L) : Perference to being passive \\& listen to an expert explain the topic.\n",
    "8. Audio (A) : How much preference is given to audio explanations (podcasts, music)\n",
    "9. Self-evaluation (SE) : Self evaluate their readiness/motivation/excitement for the course.\n",
    "10. Pre-assessment (PA): Pre-assessment of pre-requisites required for the course.\n",
    "\n",
    "Other features to be considered later to add to the complexity \\& completeness. \n",
    "- Age : Which age bracket ( [0 - 10 , 11-20, 21-30 ..... 70-80 ]\n",
    "- Gender : Male or Female. (These are 2 features)\n",
    "- Features, that can be captured in a live system: \n",
    "    - Response Times: Time taken by student to answer questions / give feedback\n",
    "    - Correctness of answer: How correct is the answer. Generally, we classify answer as either being right or wrong. Research has shown that most answer fall in between, being completely wrong or right. It a research challenge to measure the rightness of an answer \\& depends of the subject being taught. \n",
    "    - Interactions: Student interaction with the content being taught. Are they highlighting the text, bookmarking , pausing , adding notes. \n",
    "    - Forgetfulness: How well do students remember the content they were taught. \n",
    "\n",
    "\n",
    "# Content Features \n",
    "\n",
    "1. Ease of understanding (E) : How relatively easy is it to understand content. A value close to 0 implies its not easy, where as a value close to 1 implies, its comparatively easy.\n",
    "2. Simple / Intuition (I): Does the content provide a simple, intuitive understanding of the topic.\n",
    "3. Surface / In-depth (ID): Does it provide a surface level or deep understanding of the topic.\n",
    "4. Brief / Concise (C) : Is it short , to the point OR descriptive , verbose & elaborative. Learners have different levels of maintaining concentration \\& rememberance.\n",
    "5. Thorough (T): How well does the content cover the topic.\n",
    "6. Preference / Well reviewed / Well rated (R) : How well rated is the explanation. Remember to write down in education, that we envision s system where teachers would share available resources from various sources \\& are able to use it to teach their students.\n",
    "7. Theoritical / Abstract (A): How theoritical, abstract is the content\n",
    "8. Practical / Hands on (P) : Is it something that can be tried or experienced\n",
    "9. Experimental / Task-based (ETB): Does it require a task to be completed to fully understand it like collaboration with other students or some research / findings.\n",
    "\n",
    "\n",
    "# Topic Features \n",
    "\n",
    "Going forward we would also like to consider importance of a topic, which would be used by the skipping algorithm to decide whether or not its a good option to skip\n",
    "\n",
    "# Data Set \n",
    "\n",
    "- Very Small : 50 students with 10 topics\n",
    "- Small :  100 students with 25 topics\n",
    "- Medium : 200 students with 50 topics\n",
    "- Large : 400 students with 100 topics\n",
    "- Very Large : 800 students with 200 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "'''\n",
    "Class that enscapulates student & content data generators. Its uses the StudentDataGen & ContentDataGen to create data. \n",
    "'''\n",
    "class DataGenerator:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.studentDataGen = StudentDataGen()\n",
    "        self.contentDataGenerator = ContentDataGen()\n",
    "        \n",
    "    def createData(self) : \n",
    "        self.studentData = self.studentDataGen.create()\n",
    "        self.contentData , self.all_topics , self.topic_content = self.contentDataGenerator.getContentsFeatures()\n",
    "        \n",
    "        with open('student.pickle', 'wb') as student_file:\n",
    "            print('Student Data : ', self.studentData.shape)\n",
    "            pickle.dump(self.studentData, student_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "        with open('content.pickle', 'wb') as content_file:\n",
    "            print('Content Data : ', self.contentData.shape)\n",
    "            pickle.dump(self.contentData, content_file , protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "        with open('topic.pickle', 'wb') as topics_file:\n",
    "            print('Topics Data : ', self.all_topics)\n",
    "            pickle.dump(self.all_topics, topics_file , protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "        with open('topic_content.pickle', 'wb') as topic_content_file:\n",
    "            print('Topic Content Data : ', self.topic_content)\n",
    "            pickle.dump(self.topic_content, topic_content_file , protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    def createStudentData(self):\n",
    "        self.studentData =  self.studentDataGen.create()\n",
    "\n",
    "    def getStudentData(self):\n",
    "        return self.studentData\n",
    "    \n",
    "    def createContentData(self):\n",
    "        self.contentsFeatures = self.contentDataGenerator.getContentsFeatures() \n",
    "        self.topicContent = self.contentDataGenerator.getTopicContent()\n",
    "        \n",
    "    def getContentData(self):\n",
    "        return self.contentsFeatures\n",
    "    \n",
    "    def getTopicData(self):\n",
    "        return self.topicContent\n",
    "\n",
    "'''\n",
    "This is the student data generator\n",
    "'''\n",
    "class StudentDataGen:\n",
    "    def __init__(self):\n",
    "        self.number_of_students = 100 # Students taking the course. \n",
    "        # Student Preferences: Visual (V) , Text (T) , Demo-based (D) , Practical (P), Step-by-step (S) , \n",
    "        # Activity / Task based (AT), Lecture (L) , Audio (A) , Self-evaluation (SE) , Pre-assessment (PA)\n",
    "        # Students preference to learning via various ways can also be evaluated on a scale of 10, rather being binary. \n",
    "        self.student_context = ['S_V','S_T','S_D','S_P','S_S','S_AT','S_L','S_A','S_SE','S_PA']\n",
    "    \n",
    "    def create(self):\n",
    "        ## Create Student Context Data\n",
    "        student_data = np.random.uniform(0.0 , 1.0 , size=(self.number_of_students,len(self.student_context)))\n",
    "        student_data = np.round(student_data,2)\n",
    "        student_context_df = pd.DataFrame(data=student_data , columns = self.student_context)\n",
    "        return student_context_df\n",
    "    \n",
    "'''\n",
    "This is the content data generator\n",
    "'''\n",
    "class ContentDataGen:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.number_of_topics = 25 # Number of topics in the course\n",
    "        # Content Features \n",
    "        # Ease of understanding (E) , Simple / Intuitive (I) , Surface / In-depth (ID) , Brief / Concise (C), Thorough (T),\n",
    "        # Preference / Well reviewed / Well rated (R) , Theoritical / Abstract (A), Practical / Hands on (P), \n",
    "        # Experimental / Task-based (ETB)\n",
    "        # Content preference to learning via various ways can also be evaluated on a scale of 10, rather being binary. \n",
    "        self.content_context = ['C_E','C_I','C_ID','C_C','C_T','C_R','C_A','C_P','C_ETB']\n",
    "        self.no_contents_per_topic = np.random.randint(5,21,self.number_of_topics) # Variable number of contents per topic.\n",
    "    \n",
    "    def create(self):\n",
    "        all_contents = list()\n",
    "        all_topics = list()\n",
    "        topic_content = {}\n",
    "        for i,j in enumerate(self.no_contents_per_topic):\n",
    "            topic_id = \"T_\" + str(i+1) # e.g : T_10\n",
    "            content_ids = [] # Temporary variable to help map topic to content. \n",
    "            for j_1 in range(1,j+1) : # Number of contents\n",
    "                c_id = 'C_' + str(i+1) + '_' + str(j_1) # e.g : C_10_2 : Content number 2 for topics 10\n",
    "                content_ids.append(c_id)\n",
    "                all_contents.append(c_id)\n",
    "            topic_content[topic_id] = content_ids  \n",
    "            all_topics.append(topic_id)\n",
    "        return topic_content , all_topics , all_contents\n",
    "    \n",
    "    # Content related features\n",
    "    def getContentsFeatures(self):\n",
    "        self.topic_content , self.all_topics , self.all_contents = self.create()\n",
    "        content_data = np.random.uniform(0.0 , 1.0 , size=(sum(self.no_contents_per_topic),len(self.content_context)))\n",
    "        content_data = np.round(content_data,2)\n",
    "        content_context_df = pd.DataFrame(data=content_data, \n",
    "                             columns = self.content_context , index=self.all_contents)\n",
    "        return content_context_df , self.all_topics , self.topic_content\n",
    "    \n",
    "    def getTopicContent(self):\n",
    "        return self.topic_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Data :  (100, 10)\n",
      "Content Data :  (329, 9)\n",
      "Topics Data :  ['T_1', 'T_2', 'T_3', 'T_4', 'T_5', 'T_6', 'T_7', 'T_8', 'T_9', 'T_10', 'T_11', 'T_12', 'T_13', 'T_14', 'T_15', 'T_16', 'T_17', 'T_18', 'T_19', 'T_20', 'T_21', 'T_22', 'T_23', 'T_24', 'T_25']\n",
      "Topic Content Data :  {'T_10': ['C_10_1', 'C_10_2', 'C_10_3', 'C_10_4', 'C_10_5', 'C_10_6', 'C_10_7', 'C_10_8', 'C_10_9', 'C_10_10', 'C_10_11', 'C_10_12', 'C_10_13', 'C_10_14'], 'T_3': ['C_3_1', 'C_3_2', 'C_3_3', 'C_3_4', 'C_3_5', 'C_3_6', 'C_3_7', 'C_3_8', 'C_3_9', 'C_3_10', 'C_3_11', 'C_3_12', 'C_3_13', 'C_3_14', 'C_3_15', 'C_3_16', 'C_3_17'], 'T_11': ['C_11_1', 'C_11_2', 'C_11_3', 'C_11_4', 'C_11_5', 'C_11_6', 'C_11_7', 'C_11_8'], 'T_2': ['C_2_1', 'C_2_2', 'C_2_3', 'C_2_4', 'C_2_5', 'C_2_6', 'C_2_7', 'C_2_8'], 'T_18': ['C_18_1', 'C_18_2', 'C_18_3', 'C_18_4', 'C_18_5', 'C_18_6'], 'T_25': ['C_25_1', 'C_25_2', 'C_25_3', 'C_25_4', 'C_25_5', 'C_25_6', 'C_25_7', 'C_25_8', 'C_25_9', 'C_25_10', 'C_25_11', 'C_25_12', 'C_25_13', 'C_25_14'], 'T_21': ['C_21_1', 'C_21_2', 'C_21_3', 'C_21_4', 'C_21_5', 'C_21_6', 'C_21_7', 'C_21_8', 'C_21_9', 'C_21_10', 'C_21_11', 'C_21_12'], 'T_15': ['C_15_1', 'C_15_2', 'C_15_3', 'C_15_4', 'C_15_5', 'C_15_6', 'C_15_7', 'C_15_8', 'C_15_9', 'C_15_10', 'C_15_11', 'C_15_12', 'C_15_13', 'C_15_14', 'C_15_15', 'C_15_16', 'C_15_17', 'C_15_18', 'C_15_19', 'C_15_20'], 'T_12': ['C_12_1', 'C_12_2', 'C_12_3', 'C_12_4', 'C_12_5', 'C_12_6'], 'T_19': ['C_19_1', 'C_19_2', 'C_19_3', 'C_19_4', 'C_19_5', 'C_19_6', 'C_19_7', 'C_19_8', 'C_19_9', 'C_19_10', 'C_19_11', 'C_19_12', 'C_19_13'], 'T_6': ['C_6_1', 'C_6_2', 'C_6_3', 'C_6_4', 'C_6_5', 'C_6_6', 'C_6_7', 'C_6_8'], 'T_7': ['C_7_1', 'C_7_2', 'C_7_3', 'C_7_4', 'C_7_5', 'C_7_6', 'C_7_7', 'C_7_8', 'C_7_9', 'C_7_10', 'C_7_11', 'C_7_12', 'C_7_13', 'C_7_14', 'C_7_15', 'C_7_16', 'C_7_17', 'C_7_18', 'C_7_19'], 'T_1': ['C_1_1', 'C_1_2', 'C_1_3', 'C_1_4', 'C_1_5', 'C_1_6', 'C_1_7', 'C_1_8', 'C_1_9', 'C_1_10', 'C_1_11', 'C_1_12', 'C_1_13', 'C_1_14'], 'T_9': ['C_9_1', 'C_9_2', 'C_9_3', 'C_9_4', 'C_9_5', 'C_9_6', 'C_9_7', 'C_9_8', 'C_9_9'], 'T_16': ['C_16_1', 'C_16_2', 'C_16_3', 'C_16_4', 'C_16_5', 'C_16_6', 'C_16_7', 'C_16_8', 'C_16_9', 'C_16_10', 'C_16_11', 'C_16_12', 'C_16_13', 'C_16_14', 'C_16_15'], 'T_24': ['C_24_1', 'C_24_2', 'C_24_3', 'C_24_4', 'C_24_5', 'C_24_6', 'C_24_7', 'C_24_8', 'C_24_9'], 'T_17': ['C_17_1', 'C_17_2', 'C_17_3', 'C_17_4', 'C_17_5', 'C_17_6', 'C_17_7', 'C_17_8', 'C_17_9', 'C_17_10', 'C_17_11', 'C_17_12', 'C_17_13', 'C_17_14', 'C_17_15', 'C_17_16', 'C_17_17', 'C_17_18'], 'T_8': ['C_8_1', 'C_8_2', 'C_8_3', 'C_8_4', 'C_8_5', 'C_8_6', 'C_8_7', 'C_8_8', 'C_8_9', 'C_8_10', 'C_8_11', 'C_8_12', 'C_8_13', 'C_8_14', 'C_8_15', 'C_8_16', 'C_8_17', 'C_8_18', 'C_8_19', 'C_8_20'], 'T_14': ['C_14_1', 'C_14_2', 'C_14_3', 'C_14_4', 'C_14_5', 'C_14_6', 'C_14_7', 'C_14_8', 'C_14_9'], 'T_23': ['C_23_1', 'C_23_2', 'C_23_3', 'C_23_4', 'C_23_5', 'C_23_6', 'C_23_7', 'C_23_8', 'C_23_9', 'C_23_10', 'C_23_11', 'C_23_12', 'C_23_13', 'C_23_14', 'C_23_15', 'C_23_16'], 'T_20': ['C_20_1', 'C_20_2', 'C_20_3', 'C_20_4', 'C_20_5', 'C_20_6', 'C_20_7', 'C_20_8', 'C_20_9', 'C_20_10'], 'T_22': ['C_22_1', 'C_22_2', 'C_22_3', 'C_22_4', 'C_22_5', 'C_22_6', 'C_22_7', 'C_22_8'], 'T_13': ['C_13_1', 'C_13_2', 'C_13_3', 'C_13_4', 'C_13_5', 'C_13_6', 'C_13_7', 'C_13_8', 'C_13_9', 'C_13_10', 'C_13_11', 'C_13_12', 'C_13_13', 'C_13_14', 'C_13_15', 'C_13_16', 'C_13_17', 'C_13_18'], 'T_5': ['C_5_1', 'C_5_2', 'C_5_3', 'C_5_4', 'C_5_5', 'C_5_6', 'C_5_7', 'C_5_8', 'C_5_9', 'C_5_10', 'C_5_11', 'C_5_12', 'C_5_13', 'C_5_14', 'C_5_15', 'C_5_16', 'C_5_17', 'C_5_18', 'C_5_19', 'C_5_20'], 'T_4': ['C_4_1', 'C_4_2', 'C_4_3', 'C_4_4', 'C_4_5', 'C_4_6', 'C_4_7', 'C_4_8', 'C_4_9', 'C_4_10', 'C_4_11', 'C_4_12', 'C_4_13', 'C_4_14', 'C_4_15', 'C_4_16', 'C_4_17', 'C_4_18']}\n"
     ]
    }
   ],
   "source": [
    "dataGenerator = DataGenerator()\n",
    "dataGenerator.createData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_E</th>\n",
       "      <th>C_I</th>\n",
       "      <th>C_ID</th>\n",
       "      <th>C_C</th>\n",
       "      <th>C_T</th>\n",
       "      <th>C_R</th>\n",
       "      <th>C_A</th>\n",
       "      <th>C_P</th>\n",
       "      <th>C_ETB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_1_1</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C_E   C_I  C_ID   C_C   C_T   C_R   C_A   C_P  C_ETB\n",
       "C_1_1  0.45  0.72  0.31  0.05  0.91  0.75  0.06  0.88   0.97"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "file_path = os.path.join(os.path.curdir, '..' , 'dataset' , 'small')\n",
    "with open(os.path.join(file_path , 'content.pickle'), 'rb') as student_file:\n",
    "    studentContext= pickle.load(student_file)\n",
    "    \n",
    "studentContext.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
