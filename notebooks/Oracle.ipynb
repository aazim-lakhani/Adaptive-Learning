{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Omniscient Policy / Oracle\n",
    "\n",
    "This notebook represents an omniscient policy that knows all the probability distributions. This policy knows every step of the way the best decision based on its knowledge of the true distributions. It does not have to learn anything. The oracle has optimal parameters $\\theta$, hence it is expected to maximize reward in fewer rounds. \n",
    "\n",
    "Before running an experiment, you need to configure the $\\textbf{file_path}$ to set the location of the dataset. This is where we have the contextual features and the course outline (topics and content items). Configure $\\alpha$ to control exploration, $\\textbf{confidence_threshold}$ to control skipping and $\\textbf{to_csv}$ to set the file name to log the user interaction. A user interaction stores the content items present to the student, along with the expected payoff of the current and next topic in the sequence, the prediction of the skip classifier and feedback sent by a student. This is required to evaluate the learning algorithm.\n",
    "\n",
    "- Configure / validate these before you run: \n",
    "    1. File Path: Location of the dataset. \n",
    "    2. alpha: control exploration\n",
    "    3. confidence_threshold : \n",
    "    4. to_csv :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Context Shape :  (400, 10)\n",
      "Content Context Shape :  (720, 9)\n",
      "**********************************\n",
      "      S_V   S_T   S_D   S_P   S_S  S_AT   S_L   S_A  S_SE  S_PA\n",
      "0    0.95  0.21  0.14  0.98  0.22  0.86  0.93  0.62  0.61  0.22\n",
      "1    0.11  0.19  0.45  0.65  0.20  0.51  0.27  0.34  0.12  0.92\n",
      "2    0.06  0.55  0.36  0.61  0.50  0.21  0.88  0.67  0.35  0.37\n",
      "3    0.94  0.80  0.44  0.33  0.79  0.88  0.13  0.97  0.75  0.35\n",
      "4    0.28  0.32  0.52  0.02  0.24  0.54  0.96  0.62  0.87  0.64\n",
      "5    0.78  0.34  0.02  0.02  0.58  0.42  0.67  0.32  0.13  1.00\n",
      "6    0.50  0.19  0.10  0.31  0.69  0.13  0.00  0.01  0.32  0.07\n",
      "7    0.40  0.99  0.13  0.46  0.61  0.55  0.90  0.40  0.90  0.90\n",
      "8    0.94  0.84  0.02  0.97  0.30  0.34  0.19  0.08  0.52  0.91\n",
      "9    0.08  0.20  0.01  0.62  0.12  0.28  0.93  0.52  0.67  0.68\n",
      "10   0.59  0.01  0.61  0.98  0.08  0.07  0.39  0.98  0.54  0.16\n",
      "11   0.99  0.12  0.10  0.69  0.30  0.98  0.19  0.10  0.22  0.77\n",
      "12   0.68  0.28  0.38  0.98  0.11  0.48  0.80  0.06  0.90  0.71\n",
      "13   0.33  0.82  0.34  0.97  0.09  0.12  0.07  0.98  0.06  0.80\n",
      "14   0.75  0.95  0.99  0.78  0.48  0.11  0.73  0.85  0.18  0.17\n",
      "15   0.43  0.60  0.85  0.92  0.88  0.51  0.50  0.15  0.74  0.66\n",
      "16   0.93  0.16  0.14  0.57  0.29  0.09  0.81  0.73  0.46  0.51\n",
      "17   0.78  0.23  0.57  0.09  0.50  0.21  0.91  0.24  0.79  0.17\n",
      "18   0.12  0.52  0.87  0.20  0.88  0.41  0.48  0.97  0.52  0.49\n",
      "19   0.73  0.30  0.92  0.43  0.20  0.51  0.80  0.33  0.38  0.12\n",
      "20   0.94  0.35  0.21  0.57  0.40  0.95  0.99  0.44  0.65  0.18\n",
      "21   0.96  0.89  0.30  0.45  0.81  0.43  0.66  0.14  0.78  0.73\n",
      "22   0.54  0.22  0.70  0.59  0.32  0.70  0.03  0.05  0.74  0.56\n",
      "23   0.08  0.75  0.89  0.51  0.25  0.18  0.40  0.37  0.10  0.47\n",
      "24   0.67  0.48  0.90  0.54  0.69  0.10  0.64  0.66  0.65  0.68\n",
      "25   0.75  0.17  0.05  0.64  0.91  0.74  0.43  0.70  0.47  0.28\n",
      "26   0.04  0.10  0.26  0.79  0.11  0.62  0.74  0.03  0.91  0.36\n",
      "27   0.71  0.57  0.62  0.77  0.74  0.89  0.79  0.29  0.18  0.91\n",
      "28   0.43  0.85  0.23  0.94  0.17  0.15  0.09  0.40  0.63  0.44\n",
      "29   0.94  0.73  0.94  0.80  0.26  0.51  0.55  0.39  0.80  0.72\n",
      "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...\n",
      "370  0.59  0.52  0.22  0.03  0.10  0.80  0.44  0.05  0.88  0.79\n",
      "371  0.38  0.22  0.58  0.04  0.81  0.72  0.21  0.93  0.03  0.51\n",
      "372  0.59  0.68  0.16  0.59  0.29  0.29  0.88  0.81  0.41  0.86\n",
      "373  0.91  0.37  0.16  0.28  0.84  0.07  0.23  0.55  0.84  0.59\n",
      "374  0.64  0.12  0.73  0.51  0.05  0.41  0.23  0.27  0.97  0.72\n",
      "375  0.77  0.03  0.88  0.30  0.07  0.55  0.02  0.57  0.71  0.79\n",
      "376  0.01  0.62  0.09  0.52  0.31  0.49  0.60  0.71  0.22  0.86\n",
      "377  0.20  0.19  0.13  0.95  0.09  0.69  0.59  0.45  0.52  0.28\n",
      "378  0.34  0.06  1.00  0.58  0.22  0.95  0.00  0.49  0.21  0.27\n",
      "379  0.58  0.54  0.42  0.22  0.63  0.42  0.23  0.22  0.09  0.46\n",
      "380  0.35  0.36  0.64  0.39  0.82  0.28  0.16  0.95  0.60  0.57\n",
      "381  0.83  0.18  0.94  0.44  0.34  0.94  0.60  0.88  0.50  0.10\n",
      "382  0.59  0.50  0.10  0.26  0.65  0.19  0.79  0.09  0.83  0.63\n",
      "383  0.44  0.45  0.51  0.48  0.34  0.73  0.21  0.92  0.73  0.66\n",
      "384  0.54  0.15  0.13  0.05  0.99  0.33  0.23  0.43  0.34  0.81\n",
      "385  0.52  0.13  0.70  0.21  0.54  0.45  0.29  0.50  0.78  0.78\n",
      "386  0.02  0.59  0.69  0.99  0.25  0.23  0.22  0.20  0.06  0.82\n",
      "387  0.96  0.83  0.17  0.65  0.69  0.36  0.90  0.30  0.77  0.68\n",
      "388  0.88  0.07  0.02  0.50  0.94  0.63  0.18  0.26  0.42  0.59\n",
      "389  0.18  0.36  0.07  0.23  0.32  0.19  0.99  0.53  0.81  0.97\n",
      "390  0.66  0.37  0.51  0.48  0.94  0.16  0.36  0.40  0.34  0.98\n",
      "391  0.62  0.62  0.78  0.06  0.13  0.46  0.71  0.00  0.95  0.72\n",
      "392  0.15  0.92  0.87  0.35  0.91  0.69  0.31  0.06  0.69  0.52\n",
      "393  0.62  0.25  0.92  0.63  0.54  0.32  1.00  0.89  0.46  0.52\n",
      "394  0.12  1.00  0.88  0.60  0.80  0.37  0.94  0.74  0.97  0.60\n",
      "395  0.23  0.54  0.16  0.03  0.92  0.73  0.16  0.20  0.44  0.09\n",
      "396  0.94  0.15  0.27  0.76  0.24  0.63  0.89  0.73  0.92  0.00\n",
      "397  0.69  0.52  0.08  0.29  0.78  0.68  0.39  0.86  0.97  0.11\n",
      "398  0.51  0.12  0.29  0.89  0.39  0.78  0.71  0.59  0.91  0.68\n",
      "399  0.19  0.90  0.86  0.08  0.93  0.13  0.31  0.70  0.39  0.86\n",
      "\n",
      "[400 rows x 10 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "*********************************\n",
      "          C_E   C_I  C_ID   C_C   C_T   C_R   C_A   C_P  C_ETB\n",
      "C_1_1    0.34  0.51  0.68  0.29  0.75  0.20  0.65  0.34   0.72\n",
      "C_1_2    0.81  0.28  0.34  0.72  0.96  0.34  0.68  0.27   0.78\n",
      "C_1_3    0.82  0.47  0.51  0.44  0.36  0.11  0.83  0.98   0.58\n",
      "C_1_4    0.49  0.37  0.24  0.47  0.49  0.44  0.72  0.01   0.65\n",
      "C_1_5    0.58  0.64  0.52  0.86  0.39  0.65  0.44  0.90   0.27\n",
      "C_2_1    0.82  0.83  0.58  0.14  0.48  0.97  0.85  0.78   0.77\n",
      "C_2_2    0.13  0.23  0.17  0.98  0.20  0.39  0.75  0.52   0.50\n",
      "C_2_3    0.98  0.56  0.02  0.21  0.83  0.92  0.05  0.14   0.62\n",
      "C_2_4    0.69  0.31  0.87  0.98  0.97  0.06  0.68  0.82   0.15\n",
      "C_2_5    0.07  0.30  0.21  0.78  0.26  0.64  0.02  0.07   0.22\n",
      "C_2_6    0.80  0.12  0.29  0.86  0.08  0.47  0.80  0.38   0.49\n",
      "C_2_7    0.38  0.27  0.11  0.76  0.59  0.00  0.60  0.89   0.63\n",
      "C_3_1    0.35  0.48  0.58  0.95  0.97  0.87  0.19  0.81   0.20\n",
      "C_3_2    0.61  0.34  0.66  0.94  0.66  0.58  0.58  0.14   0.56\n",
      "C_3_3    0.85  0.87  0.48  0.22  0.91  0.47  0.18  0.12   0.11\n",
      "C_3_4    0.46  0.79  0.78  0.34  0.04  0.87  0.58  0.16   0.87\n",
      "C_3_5    0.67  0.94  0.24  0.25  0.39  0.94  0.61  0.22   0.73\n",
      "C_3_6    0.89  0.61  0.02  0.25  0.48  0.52  0.12  0.59   0.76\n",
      "C_4_1    0.39  0.99  0.91  0.10  0.05  0.16  0.24  0.24   0.20\n",
      "C_4_2    0.57  0.15  0.56  0.25  0.76  0.88  0.54  0.42   0.91\n",
      "C_4_3    0.85  0.41  0.37  0.32  0.67  0.49  0.57  0.20   0.18\n",
      "C_4_4    0.54  0.58  0.25  0.67  0.61  0.29  0.14  0.03   0.77\n",
      "C_4_5    0.24  0.06  0.48  0.04  0.50  0.00  0.99  0.18   0.29\n",
      "C_4_6    0.53  0.46  0.22  0.77  0.88  0.92  0.45  0.06   0.25\n",
      "C_4_7    0.43  0.04  0.20  0.90  0.16  0.15  0.17  0.08   0.91\n",
      "C_5_1    0.96  0.99  0.04  0.46  0.30  0.04  0.73  0.99   0.75\n",
      "C_5_2    0.76  0.82  0.47  0.99  0.39  0.29  0.90  0.21   0.32\n",
      "C_5_3    0.36  0.26  0.07  0.77  0.68  0.73  0.21  0.93   0.09\n",
      "C_5_4    0.74  0.20  0.09  0.23  0.39  0.79  0.68  0.08   0.96\n",
      "C_5_5    0.37  0.06  0.80  0.10  0.84  0.82  0.04  0.30   0.15\n",
      "...       ...   ...   ...   ...   ...   ...   ...   ...    ...\n",
      "C_96_7   0.83  0.68  0.40  0.14  0.65  0.11  1.00  0.79   0.45\n",
      "C_96_8   0.82  0.44  0.78  0.78  0.48  0.99  0.01  0.08   0.10\n",
      "C_96_9   0.10  0.82  0.42  0.54  0.94  0.35  0.57  0.55   0.46\n",
      "C_96_10  0.83  0.23  0.37  0.36  0.53  0.60  0.74  0.42   0.58\n",
      "C_97_1   0.47  0.88  0.85  0.31  0.78  0.90  0.79  0.91   0.56\n",
      "C_97_2   0.27  0.99  0.82  0.18  0.64  0.17  0.20  0.03   0.44\n",
      "C_97_3   0.52  0.24  0.92  0.60  0.55  0.56  0.30  0.90   0.87\n",
      "C_97_4   0.72  0.63  0.19  0.73  0.51  0.06  0.20  0.42   0.47\n",
      "C_97_5   0.11  0.75  0.61  0.36  0.34  0.95  0.92  0.38   0.89\n",
      "C_98_1   0.20  0.90  0.05  0.09  0.21  0.94  0.51  0.09   0.99\n",
      "C_98_2   0.78  0.94  0.14  0.23  0.57  0.58  0.50  0.23   0.90\n",
      "C_98_3   0.74  0.44  0.03  0.64  0.73  0.50  0.02  0.54   0.43\n",
      "C_98_4   0.75  0.32  0.98  0.30  0.90  0.86  0.21  0.76   0.94\n",
      "C_98_5   0.06  0.53  0.76  0.66  0.03  0.91  0.37  0.95   0.81\n",
      "C_98_6   0.47  0.68  0.84  0.28  0.51  0.20  0.95  0.19   0.52\n",
      "C_99_1   0.48  0.69  0.63  0.96  0.77  0.86  0.18  0.02   0.17\n",
      "C_99_2   0.77  0.89  0.75  0.92  0.68  0.51  0.55  0.56   0.94\n",
      "C_99_3   0.88  0.37  0.02  0.37  0.79  0.89  0.33  0.98   0.00\n",
      "C_99_4   0.12  0.44  0.76  0.90  0.48  0.55  0.06  0.22   0.54\n",
      "C_99_5   0.94  0.20  0.27  0.24  0.77  0.35  0.52  0.80   0.58\n",
      "C_99_6   0.04  0.62  0.94  0.03  0.48  0.19  0.83  0.15   0.51\n",
      "C_99_7   0.59  0.80  0.45  0.74  0.90  0.22  0.83  0.99   0.63\n",
      "C_99_8   0.75  0.13  0.51  0.75  0.69  0.10  0.57  0.27   0.79\n",
      "C_99_9   0.21  0.10  0.68  0.17  0.13  0.79  0.48  0.56   0.42\n",
      "C_100_1  0.48  0.17  0.34  0.41  0.75  0.32  0.15  0.94   0.64\n",
      "C_100_2  0.91  0.76  0.17  0.14  0.50  0.63  0.94  0.94   0.56\n",
      "C_100_3  0.67  0.04  0.26  0.46  0.94  0.30  0.43  0.04   0.28\n",
      "C_100_4  0.51  0.74  0.55  1.00  0.82  0.80  0.47  0.93   0.52\n",
      "C_100_5  0.80  0.40  0.53  0.55  0.91  0.80  0.13  0.20   0.79\n",
      "C_100_6  0.79  0.67  0.64  0.61  0.11  0.20  0.23  0.66   0.15\n",
      "\n",
      "[720 rows x 9 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "*********************************\n",
      "['T_1', 'T_2', 'T_3', 'T_4', 'T_5', 'T_6', 'T_7', 'T_8', 'T_9', 'T_10', 'T_11', 'T_12', 'T_13', 'T_14', 'T_15', 'T_16', 'T_17', 'T_18', 'T_19', 'T_20', 'T_21', 'T_22', 'T_23', 'T_24', 'T_25', 'T_26', 'T_27', 'T_28', 'T_29', 'T_30', 'T_31', 'T_32', 'T_33', 'T_34', 'T_35', 'T_36', 'T_37', 'T_38', 'T_39', 'T_40', 'T_41', 'T_42', 'T_43', 'T_44', 'T_45', 'T_46', 'T_47', 'T_48', 'T_49', 'T_50', 'T_51', 'T_52', 'T_53', 'T_54', 'T_55', 'T_56', 'T_57', 'T_58', 'T_59', 'T_60', 'T_61', 'T_62', 'T_63', 'T_64', 'T_65', 'T_66', 'T_67', 'T_68', 'T_69', 'T_70', 'T_71', 'T_72', 'T_73', 'T_74', 'T_75', 'T_76', 'T_77', 'T_78', 'T_79', 'T_80', 'T_81', 'T_82', 'T_83', 'T_84', 'T_85', 'T_86', 'T_87', 'T_88', 'T_89', 'T_90', 'T_91', 'T_92', 'T_93', 'T_94', 'T_95', 'T_96', 'T_97', 'T_98', 'T_99', 'T_100']\n",
      "<class 'list'>\n",
      "*********************************\n",
      "{'T_1': ['C_1_1', 'C_1_2', 'C_1_3', 'C_1_4', 'C_1_5'], 'T_71': ['C_71_1', 'C_71_2', 'C_71_3', 'C_71_4', 'C_71_5', 'C_71_6'], 'T_67': ['C_67_1', 'C_67_2', 'C_67_3', 'C_67_4', 'C_67_5'], 'T_37': ['C_37_1', 'C_37_2', 'C_37_3', 'C_37_4', 'C_37_5', 'C_37_6', 'C_37_7', 'C_37_8', 'C_37_9'], 'T_93': ['C_93_1', 'C_93_2', 'C_93_3', 'C_93_4', 'C_93_5', 'C_93_6', 'C_93_7', 'C_93_8', 'C_93_9', 'C_93_10'], 'T_29': ['C_29_1', 'C_29_2', 'C_29_3', 'C_29_4', 'C_29_5', 'C_29_6', 'C_29_7'], 'T_43': ['C_43_1', 'C_43_2', 'C_43_3', 'C_43_4', 'C_43_5', 'C_43_6', 'C_43_7', 'C_43_8'], 'T_32': ['C_32_1', 'C_32_2', 'C_32_3', 'C_32_4', 'C_32_5'], 'T_51': ['C_51_1', 'C_51_2', 'C_51_3', 'C_51_4', 'C_51_5'], 'T_45': ['C_45_1', 'C_45_2', 'C_45_3', 'C_45_4', 'C_45_5', 'C_45_6', 'C_45_7', 'C_45_8'], 'T_38': ['C_38_1', 'C_38_2', 'C_38_3', 'C_38_4', 'C_38_5', 'C_38_6', 'C_38_7', 'C_38_8', 'C_38_9'], 'T_57': ['C_57_1', 'C_57_2', 'C_57_3', 'C_57_4', 'C_57_5', 'C_57_6', 'C_57_7', 'C_57_8', 'C_57_9', 'C_57_10'], 'T_69': ['C_69_1', 'C_69_2', 'C_69_3', 'C_69_4', 'C_69_5'], 'T_92': ['C_92_1', 'C_92_2', 'C_92_3', 'C_92_4', 'C_92_5', 'C_92_6', 'C_92_7', 'C_92_8', 'C_92_9'], 'T_74': ['C_74_1', 'C_74_2', 'C_74_3', 'C_74_4', 'C_74_5'], 'T_42': ['C_42_1', 'C_42_2', 'C_42_3', 'C_42_4', 'C_42_5', 'C_42_6', 'C_42_7', 'C_42_8', 'C_42_9'], 'T_34': ['C_34_1', 'C_34_2', 'C_34_3', 'C_34_4', 'C_34_5', 'C_34_6', 'C_34_7', 'C_34_8'], 'T_26': ['C_26_1', 'C_26_2', 'C_26_3', 'C_26_4', 'C_26_5', 'C_26_6'], 'T_40': ['C_40_1', 'C_40_2', 'C_40_3', 'C_40_4', 'C_40_5', 'C_40_6', 'C_40_7'], 'T_19': ['C_19_1', 'C_19_2', 'C_19_3', 'C_19_4', 'C_19_5', 'C_19_6', 'C_19_7', 'C_19_8', 'C_19_9', 'C_19_10'], 'T_27': ['C_27_1', 'C_27_2', 'C_27_3', 'C_27_4', 'C_27_5', 'C_27_6', 'C_27_7', 'C_27_8', 'C_27_9'], 'T_35': ['C_35_1', 'C_35_2', 'C_35_3', 'C_35_4', 'C_35_5', 'C_35_6', 'C_35_7'], 'T_68': ['C_68_1', 'C_68_2', 'C_68_3', 'C_68_4', 'C_68_5', 'C_68_6'], 'T_85': ['C_85_1', 'C_85_2', 'C_85_3', 'C_85_4', 'C_85_5'], 'T_20': ['C_20_1', 'C_20_2', 'C_20_3', 'C_20_4', 'C_20_5', 'C_20_6', 'C_20_7', 'C_20_8', 'C_20_9', 'C_20_10'], 'T_50': ['C_50_1', 'C_50_2', 'C_50_3', 'C_50_4', 'C_50_5', 'C_50_6', 'C_50_7', 'C_50_8', 'C_50_9', 'C_50_10'], 'T_64': ['C_64_1', 'C_64_2', 'C_64_3', 'C_64_4', 'C_64_5', 'C_64_6', 'C_64_7', 'C_64_8'], 'T_49': ['C_49_1', 'C_49_2', 'C_49_3', 'C_49_4', 'C_49_5', 'C_49_6'], 'T_79': ['C_79_1', 'C_79_2', 'C_79_3', 'C_79_4', 'C_79_5', 'C_79_6', 'C_79_7', 'C_79_8'], 'T_47': ['C_47_1', 'C_47_2', 'C_47_3', 'C_47_4', 'C_47_5', 'C_47_6'], 'T_10': ['C_10_1', 'C_10_2', 'C_10_3', 'C_10_4', 'C_10_5', 'C_10_6', 'C_10_7', 'C_10_8', 'C_10_9', 'C_10_10'], 'T_28': ['C_28_1', 'C_28_2', 'C_28_3', 'C_28_4', 'C_28_5', 'C_28_6', 'C_28_7', 'C_28_8', 'C_28_9'], 'T_25': ['C_25_1', 'C_25_2', 'C_25_3', 'C_25_4', 'C_25_5', 'C_25_6'], 'T_60': ['C_60_1', 'C_60_2', 'C_60_3', 'C_60_4', 'C_60_5', 'C_60_6', 'C_60_7'], 'T_89': ['C_89_1', 'C_89_2', 'C_89_3', 'C_89_4', 'C_89_5'], 'T_87': ['C_87_1', 'C_87_2', 'C_87_3', 'C_87_4', 'C_87_5', 'C_87_6', 'C_87_7'], 'T_58': ['C_58_1', 'C_58_2', 'C_58_3', 'C_58_4', 'C_58_5', 'C_58_6'], 'T_91': ['C_91_1', 'C_91_2', 'C_91_3', 'C_91_4', 'C_91_5'], 'T_96': ['C_96_1', 'C_96_2', 'C_96_3', 'C_96_4', 'C_96_5', 'C_96_6', 'C_96_7', 'C_96_8', 'C_96_9', 'C_96_10'], 'T_80': ['C_80_1', 'C_80_2', 'C_80_3', 'C_80_4', 'C_80_5', 'C_80_6'], 'T_90': ['C_90_1', 'C_90_2', 'C_90_3', 'C_90_4', 'C_90_5', 'C_90_6', 'C_90_7'], 'T_55': ['C_55_1', 'C_55_2', 'C_55_3', 'C_55_4', 'C_55_5', 'C_55_6', 'C_55_7', 'C_55_8', 'C_55_9'], 'T_65': ['C_65_1', 'C_65_2', 'C_65_3', 'C_65_4', 'C_65_5'], 'T_5': ['C_5_1', 'C_5_2', 'C_5_3', 'C_5_4', 'C_5_5', 'C_5_6', 'C_5_7'], 'T_33': ['C_33_1', 'C_33_2', 'C_33_3', 'C_33_4', 'C_33_5', 'C_33_6'], 'T_3': ['C_3_1', 'C_3_2', 'C_3_3', 'C_3_4', 'C_3_5', 'C_3_6'], 'T_46': ['C_46_1', 'C_46_2', 'C_46_3', 'C_46_4', 'C_46_5'], 'T_44': ['C_44_1', 'C_44_2', 'C_44_3', 'C_44_4', 'C_44_5', 'C_44_6', 'C_44_7', 'C_44_8'], 'T_66': ['C_66_1', 'C_66_2', 'C_66_3', 'C_66_4', 'C_66_5', 'C_66_6', 'C_66_7'], 'T_12': ['C_12_1', 'C_12_2', 'C_12_3', 'C_12_4', 'C_12_5'], 'T_23': ['C_23_1', 'C_23_2', 'C_23_3', 'C_23_4', 'C_23_5', 'C_23_6', 'C_23_7', 'C_23_8', 'C_23_9'], 'T_4': ['C_4_1', 'C_4_2', 'C_4_3', 'C_4_4', 'C_4_5', 'C_4_6', 'C_4_7'], 'T_15': ['C_15_1', 'C_15_2', 'C_15_3', 'C_15_4', 'C_15_5', 'C_15_6', 'C_15_7', 'C_15_8', 'C_15_9'], 'T_97': ['C_97_1', 'C_97_2', 'C_97_3', 'C_97_4', 'C_97_5'], 'T_62': ['C_62_1', 'C_62_2', 'C_62_3', 'C_62_4', 'C_62_5', 'C_62_6'], 'T_9': ['C_9_1', 'C_9_2', 'C_9_3', 'C_9_4', 'C_9_5', 'C_9_6', 'C_9_7', 'C_9_8', 'C_9_9'], 'T_81': ['C_81_1', 'C_81_2', 'C_81_3', 'C_81_4', 'C_81_5', 'C_81_6', 'C_81_7', 'C_81_8'], 'T_61': ['C_61_1', 'C_61_2', 'C_61_3', 'C_61_4', 'C_61_5', 'C_61_6', 'C_61_7', 'C_61_8', 'C_61_9'], 'T_36': ['C_36_1', 'C_36_2', 'C_36_3', 'C_36_4', 'C_36_5', 'C_36_6', 'C_36_7'], 'T_59': ['C_59_1', 'C_59_2', 'C_59_3', 'C_59_4', 'C_59_5', 'C_59_6'], 'T_7': ['C_7_1', 'C_7_2', 'C_7_3', 'C_7_4', 'C_7_5', 'C_7_6', 'C_7_7', 'C_7_8', 'C_7_9', 'C_7_10'], 'T_17': ['C_17_1', 'C_17_2', 'C_17_3', 'C_17_4', 'C_17_5', 'C_17_6', 'C_17_7'], 'T_86': ['C_86_1', 'C_86_2', 'C_86_3', 'C_86_4', 'C_86_5', 'C_86_6', 'C_86_7'], 'T_2': ['C_2_1', 'C_2_2', 'C_2_3', 'C_2_4', 'C_2_5', 'C_2_6', 'C_2_7'], 'T_83': ['C_83_1', 'C_83_2', 'C_83_3', 'C_83_4', 'C_83_5'], 'T_95': ['C_95_1', 'C_95_2', 'C_95_3', 'C_95_4', 'C_95_5', 'C_95_6'], 'T_100': ['C_100_1', 'C_100_2', 'C_100_3', 'C_100_4', 'C_100_5', 'C_100_6'], 'T_21': ['C_21_1', 'C_21_2', 'C_21_3', 'C_21_4', 'C_21_5', 'C_21_6', 'C_21_7', 'C_21_8'], 'T_41': ['C_41_1', 'C_41_2', 'C_41_3', 'C_41_4', 'C_41_5', 'C_41_6', 'C_41_7'], 'T_22': ['C_22_1', 'C_22_2', 'C_22_3', 'C_22_4', 'C_22_5', 'C_22_6'], 'T_78': ['C_78_1', 'C_78_2', 'C_78_3', 'C_78_4', 'C_78_5'], 'T_84': ['C_84_1', 'C_84_2', 'C_84_3', 'C_84_4', 'C_84_5', 'C_84_6', 'C_84_7', 'C_84_8'], 'T_94': ['C_94_1', 'C_94_2', 'C_94_3', 'C_94_4', 'C_94_5', 'C_94_6', 'C_94_7', 'C_94_8', 'C_94_9'], 'T_11': ['C_11_1', 'C_11_2', 'C_11_3', 'C_11_4', 'C_11_5', 'C_11_6', 'C_11_7', 'C_11_8', 'C_11_9'], 'T_99': ['C_99_1', 'C_99_2', 'C_99_3', 'C_99_4', 'C_99_5', 'C_99_6', 'C_99_7', 'C_99_8', 'C_99_9'], 'T_98': ['C_98_1', 'C_98_2', 'C_98_3', 'C_98_4', 'C_98_5', 'C_98_6'], 'T_77': ['C_77_1', 'C_77_2', 'C_77_3', 'C_77_4', 'C_77_5', 'C_77_6', 'C_77_7', 'C_77_8', 'C_77_9'], 'T_88': ['C_88_1', 'C_88_2', 'C_88_3', 'C_88_4', 'C_88_5', 'C_88_6'], 'T_72': ['C_72_1', 'C_72_2', 'C_72_3', 'C_72_4', 'C_72_5', 'C_72_6', 'C_72_7'], 'T_31': ['C_31_1', 'C_31_2', 'C_31_3', 'C_31_4', 'C_31_5'], 'T_52': ['C_52_1', 'C_52_2', 'C_52_3', 'C_52_4', 'C_52_5', 'C_52_6', 'C_52_7', 'C_52_8', 'C_52_9'], 'T_13': ['C_13_1', 'C_13_2', 'C_13_3', 'C_13_4', 'C_13_5', 'C_13_6', 'C_13_7', 'C_13_8', 'C_13_9'], 'T_54': ['C_54_1', 'C_54_2', 'C_54_3', 'C_54_4', 'C_54_5'], 'T_53': ['C_53_1', 'C_53_2', 'C_53_3', 'C_53_4', 'C_53_5', 'C_53_6', 'C_53_7'], 'T_76': ['C_76_1', 'C_76_2', 'C_76_3', 'C_76_4', 'C_76_5', 'C_76_6', 'C_76_7', 'C_76_8', 'C_76_9'], 'T_73': ['C_73_1', 'C_73_2', 'C_73_3', 'C_73_4', 'C_73_5', 'C_73_6', 'C_73_7', 'C_73_8'], 'T_16': ['C_16_1', 'C_16_2', 'C_16_3', 'C_16_4', 'C_16_5', 'C_16_6', 'C_16_7'], 'T_18': ['C_18_1', 'C_18_2', 'C_18_3', 'C_18_4', 'C_18_5', 'C_18_6', 'C_18_7', 'C_18_8', 'C_18_9'], 'T_63': ['C_63_1', 'C_63_2', 'C_63_3', 'C_63_4', 'C_63_5', 'C_63_6', 'C_63_7', 'C_63_8'], 'T_82': ['C_82_1', 'C_82_2', 'C_82_3', 'C_82_4', 'C_82_5', 'C_82_6', 'C_82_7'], 'T_8': ['C_8_1', 'C_8_2', 'C_8_3', 'C_8_4', 'C_8_5'], 'T_30': ['C_30_1', 'C_30_2', 'C_30_3', 'C_30_4', 'C_30_5', 'C_30_6', 'C_30_7', 'C_30_8'], 'T_24': ['C_24_1', 'C_24_2', 'C_24_3', 'C_24_4', 'C_24_5', 'C_24_6'], 'T_48': ['C_48_1', 'C_48_2', 'C_48_3', 'C_48_4', 'C_48_5', 'C_48_6', 'C_48_7'], 'T_56': ['C_56_1', 'C_56_2', 'C_56_3', 'C_56_4', 'C_56_5', 'C_56_6'], 'T_14': ['C_14_1', 'C_14_2', 'C_14_3', 'C_14_4', 'C_14_5', 'C_14_6', 'C_14_7'], 'T_70': ['C_70_1', 'C_70_2', 'C_70_3', 'C_70_4', 'C_70_5', 'C_70_6'], 'T_39': ['C_39_1', 'C_39_2', 'C_39_3', 'C_39_4', 'C_39_5', 'C_39_6'], 'T_75': ['C_75_1', 'C_75_2', 'C_75_3', 'C_75_4', 'C_75_5', 'C_75_6', 'C_75_7', 'C_75_8', 'C_75_9', 'C_75_10'], 'T_6': ['C_6_1', 'C_6_2', 'C_6_3', 'C_6_4', 'C_6_5', 'C_6_6', 'C_6_7']}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "import os,pickle\n",
    "\n",
    "# file_path = os.path.join(os.path.curdir, '..' , 'dataset' , 'very_small')\n",
    "# file_path = os.path.join(os.path.curdir, '..' , 'dataset' , 'small')\n",
    "# file_path = os.path.join(os.path.curdir, '..' , 'dataset' , 'medium')\n",
    "file_path = os.path.join(os.path.curdir, '..' , 'dataset' , 'large')\n",
    "# file_path = os.path.join(os.path.curdir, '..' , 'dataset' , 'very_large')\n",
    "'''\n",
    "Context data for learning\n",
    "'''\n",
    "class Context:\n",
    "    \"\"\"\n",
    "    Contextual information required by contextual bandit algorithms to make better predictions. It enscapsulates all data\n",
    "    about the student , topics & content to experiment with the oracle.\n",
    "    \"\"\"\n",
    "   \n",
    "    def getStudentContext(self):\n",
    "        \"\"\"\n",
    "        Student Preferences: \n",
    "        Visual (S_V) , Text (S_T) , Demo-based (S_D) , Practical (S_P), Step-by-step (S_S) ,Activity / Task based (S_AT), \n",
    "        Lecture (S_L) , Audio (S_A) , Self-evaluation (S_SE) , Pre-assessment (S_PA)\n",
    "        Students preference to learning via various ways are evaluated on a scale from 0 to 1, rather being binary. \n",
    "        \"\"\"\n",
    "        return self.studentContext\n",
    "    \n",
    "    def setStudentContext(self):\n",
    "        \"\"\"\n",
    "        Load the student data\n",
    "        \"\"\"\n",
    "        with open(os.path.join(file_path , 'student.pickle'), 'rb') as student_file:\n",
    "            self.studentContext= pickle.load(student_file)\n",
    "    \n",
    "    def getContentContext(self):\n",
    "        \"\"\"\n",
    "        Content Features \n",
    "        Ease of understanding (C_E), Simple / Intuitive (C_I), Surface / In-depth (C_ID), Brief / Concise (C_C), \n",
    "        Thorough (C_T), Preference / Well reviewed / Well rated (C_R), Theoritical / Abstract (C_A), \n",
    "        Practical / Hands on (C_P), Experimental / Task-based (C_ETB)\n",
    "        Content preference to learning via various ways are evaluated on a scale from 0 to 1, rather being binary. \n",
    "        \"\"\"\n",
    "        return self.contentContext\n",
    "   \n",
    "    def setContentContext(self):\n",
    "        \"\"\"\n",
    "        Load the content data\n",
    "        \"\"\"\n",
    "        with open(os.path.join(file_path ,'content.pickle'), 'rb') as content_file:\n",
    "            self.contentContext= pickle.load(content_file)\n",
    "        \n",
    "    def getTopic(self):\n",
    "        \"\"\"\n",
    "        Gives the topics part of the course.\n",
    "        \"\"\"\n",
    "        return self.topic\n",
    "    \n",
    "    def setTopic(self):\n",
    "        \"\"\"\n",
    "        Loads the topics part of the course\n",
    "        \"\"\"\n",
    "        with open(os.path.join(file_path ,'topic.pickle'), 'rb') as topic_file:\n",
    "            self.topic = pickle.load(topic_file)\n",
    "    \n",
    "    def getTopicContent(self):\n",
    "        \"\"\"\n",
    "         Gets the topic content. topic_content is a map of topics to content. So for every topic, it gives the content \n",
    "         available for the topic. In education parlance, for any given topic, it shows the different ways of teaching this\n",
    "         topic (via contents)\n",
    "        \"\"\"\n",
    "        return self.topic_content\n",
    "    \n",
    "    def setTopicContent(self):\n",
    "        \"\"\"\n",
    "        Sets the topic_content variable to the one in the serialized object. topic_content is a map of topics to content. So\n",
    "        for every topic, it gives the content available for the topic. In education parlance, for any given topic, it shows\n",
    "        the different ways of teaching this topic (via contents)\n",
    "        \"\"\"\n",
    "        with open(os.path.join(file_path ,'topic_content.pickle'), 'rb') as topic_content_file:\n",
    "            self.topic_content= pickle.load(topic_content_file)\n",
    "                \n",
    "    def prepareContext(self,studentContext,contentContext):\n",
    "        \"\"\"\n",
    "           Given the student & content context available for a round, this method combines them to form a single contextual\n",
    "           variable\n",
    "           \n",
    "           Inputs : \n",
    "           \n",
    "           studentContext: Student contextual information.\n",
    "           contentContext: Contents contextual information. \n",
    "           \n",
    "           Returns :\n",
    "           \n",
    "           context : A combined output of student & content context.\n",
    "        \"\"\"\n",
    "        context = pd.DataFrame() \n",
    "        for content in list(contentContext.index):\n",
    "            c = pd.Series()\n",
    "            c = c.append([studentContext,contentContext.loc[content]]) # Combine student & content. \n",
    "            c['Content_id'] = content\n",
    "            context = context.append(c, ignore_index=True)\n",
    "        context = context.set_index('Content_id')\n",
    "        return context\n",
    "    \n",
    "    def loadData(self):\n",
    "        \"\"\"\n",
    "        Method used to test data retrieval. Data generator handles the data generation. This method checks we can retrieve\n",
    "        data. This is a dummy method used to test data retrieval. Its not invoked in the main program.\n",
    "        \"\"\"\n",
    "        self.setStudentContext()\n",
    "        self.setContentContext()\n",
    "        self.setTopic()\n",
    "        self.setTopicContent()\n",
    "        print(\"Student Context Shape : \", self.getStudentContext().shape)\n",
    "        print(\"Content Context Shape : \", self.getContentContext().shape)\n",
    "        print(\"**********************************\")\n",
    "        print(self.getStudentContext())\n",
    "        print(type(self.getStudentContext()))\n",
    "        print('*********************************')\n",
    "        print(self.getContentContext())\n",
    "        print(type(self.getContentContext()))\n",
    "        print('*********************************')\n",
    "        print(self.getTopic())\n",
    "        print(type(self.getTopic()))\n",
    "        print('*********************************')\n",
    "        print(self.getTopicContent())\n",
    "        print(type(self.getTopicContent()))\n",
    "                \n",
    "c_test = Context()\n",
    "c_test.loadData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skip Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online Stochastic Gradient Descent. This classifier decides whether or not to skip to the next topic. \n",
    "# TO-DO : Change loss functions (Log,Hinge,Others) to find if they impact performance. Try different values of parameters \n",
    "# For instance SGD has a parameter alpha, SVM has a parameter C. To optimize, you can train a mini-batch of samples, \n",
    "# rather than one data point at a time. Try different values of learning_rate. Look at the class_weight parameter if you \n",
    "# want to give more weight to samples of one class over the other. Need to understand about warm_start parameter\n",
    "# We need to record predictions made by the classifier to evaluate its performance over rounds.\n",
    "from sklearn import linear_model\n",
    "class SkipClassifier:\n",
    "    \"\"\"\n",
    "    A classifier which gives prediction, whether or not to move to the next topic. This is important, because we want \n",
    "    students to learn content which the algorithm is confident would help the student learn. The skip classifier is trained\n",
    "    online, hence we use a confidence threshold, to be conservative & minimize skipping topics. Skipping is not preferred, \n",
    "    but if the classifier is confident the next round would help gain higher rewards, then we should skip. Ideally, we want \n",
    "    to consider skipping after the first pulled arm has failed, to avoid frustrating the student. \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.clf = linear_model.SGDClassifier()\n",
    "        self.clf.partial_fit(np.array([[0,0,0,0,0,0,0,0,0,0,0,0]]),np.array([0]),classes=np.array([0,1])) # Used to initialize the skip classifier\n",
    "#         if os.path.exists('skip_classifier_oracle_large.sav'):\n",
    "#             self.clf = pickle.load(open('skip_classifier_oracle.sav', 'rb'))\n",
    "#         else:\n",
    "#             self.clf = linear_model.SGDClassifier()\n",
    "#             self.clf.partial_fit(np.array([[0,0,0,0,0,0,0,0,0,0,0,0]]),np.array([0]),classes=np.array([0,1])) # Used to initialize the skip classifier\n",
    "# #         self.classifier_lock = threading.Lock()\n",
    "        \n",
    "        \n",
    "    def check_fitted(self,clf): \n",
    "        \"\"\"\n",
    "        Check if the classifier is fit before asking for prediction. Our classifier is trained in online mode, hence it would\n",
    "        be asked to predict before fitting. This method makes sure we only ask for prediction after a data point has been \n",
    "        fit to the estimator/model\n",
    "        \"\"\"\n",
    "        return hasattr(clf, \"classes_\")\n",
    "    \n",
    "    def train(self,student,pta,next_topic_pta,label):\n",
    "        \"\"\"\n",
    "        Used to train the classifier in online mode, over every data point. In future we might want to consider training in \n",
    "        mini-batches, rather than for every data point. \n",
    "        \"\"\"\n",
    "        X = pd.Series()\n",
    "        X = X.append([student,pd.Series([pta,next_topic_pta],index=['pta','next_topic_pta'])])\n",
    "        X = np.array([X.values])\n",
    "        Y = np.array([label])\n",
    "        self.clf = self.clf.partial_fit(X,Y)\n",
    "        pickle.dump(self.clf, open('skip_classifier_oracle_large.sav', 'wb'))\n",
    "               \n",
    "    def predict(self,student,pta,next_topic_pta):\n",
    "        \"\"\"\n",
    "        Gets predictions from the classifier, along with the confidence score to help determine the reliability / confidence\n",
    "        level of the prediction being made. \n",
    "        \"\"\"\n",
    "        X = pd.Series()\n",
    "        X = X.append([student,pd.Series([pta,next_topic_pta],index=['pta','next_topic_pta'])])\n",
    "        if self.check_fitted(self.clf):\n",
    "            Y = self.clf.predict([X.values])[0]\n",
    "            confidence_score = self.clf.decision_function([X.values])[0]\n",
    "        else:\n",
    "            Y = 0\n",
    "            confidence_score = 0\n",
    "        return int(Y) , confidence_score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SkipTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipTopic:\n",
    "    \"\"\"\n",
    "    A wrapper around the Skip Classifier to validate the inputs, before sending it to Skip Classifier for prediction. \n",
    "    It post-processes the results of the prediction made by skip classifier to check for confidence threshold, \n",
    "    before sending out the decision to skip or not. \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the SkipTopic class & sets confidence threshold to make confident skip decisions.\n",
    "        \"\"\"\n",
    "        self.skipClassifier = SkipClassifier()\n",
    "        self.confidence_threshold = 100 # It the confidence score returned by the classifier is greater than this, then we trust in the decision made by the classifier. \n",
    "        self.threshold_updated_count = 1\n",
    "        self.skip_topic_lock = threading.Lock()\n",
    "                \n",
    "    def skipTopic(self,student,pta,topic_number,context_obj,topic_content,oracle):\n",
    "        \"\"\"\n",
    "        Pre-validates the topic number before asking the skip classifier for a prediction. Then checks the confidence \n",
    "        of the prediction before sending out the decision to skip or not. \n",
    "        \"\"\"\n",
    "        contentContext = context_obj.getContentContext() # Get the content dataframe.\n",
    "        topic = context_obj.getTopic() # Get the topic list. \n",
    "        current_topic_index = topic.index(topic_number) # Get the index number of the current topic\n",
    "        next_topic_index = current_topic_index + 1\n",
    "        next_topic = '' # Initialized to make it accessible outside the if statement. \n",
    "        if next_topic_index < len(topic): # Check to see if we're going out of bounds\n",
    "            next_topic = topic[next_topic_index]\n",
    "            next_topic_contents = topic_content[next_topic]\n",
    "            t_c = contentContext.loc[next_topic_contents]\n",
    "            X = context_obj.prepareContext(student,t_c)\n",
    "            arm_pulled , next_topic_pta = oracle.expectedPayoff(X,next_topic_contents)\n",
    "        else:\n",
    "            # Will be going out of bounds. Current topic is the last topic. No more topics to complete. \n",
    "            next_topic_pta = 0\n",
    "        actual_decision , confidence_score = self.skipClassifier.predict(student,pta,next_topic_pta)\n",
    "        if actual_decision and confidence_score > self.confidence_threshold:\n",
    "            skip_decision = 1\n",
    "        else:\n",
    "            skip_decision = 0\n",
    "        return actual_decision,confidence_score,skip_decision,next_topic_pta\n",
    "\n",
    "    def setLabel(self,actual_payoff):\n",
    "        \"\"\"\n",
    "        Sets the label for training the skip classifier\n",
    "        \"\"\"\n",
    "#         if actual_payoff == -1:\n",
    "        if actual_payoff == 0:\n",
    "            label = 1\n",
    "        if actual_payoff == 1:\n",
    "            label = 0\n",
    "        return label\n",
    "    \n",
    "    def train(self,student,pta,pta_next_topic,label):\n",
    "        \"\"\"\n",
    "        Training the skip classifier\n",
    "        \"\"\"\n",
    "        self.skipClassifier.train(student,pta,pta_next_topic,label)   \n",
    "        \n",
    "    def updateConfidenceThreshold(self , rounds):\n",
    "        if np.log10(rounds) > self.threshold_updated_count : \n",
    "            self.confidence_threshold /= np.log10(rounds)\n",
    "            self.threshold_updated_count += 1\n",
    "            with self.skip_topic_lock:\n",
    "                print(\"self.confidence_threshold : {0} and self.threshold_updated_count : {1}\".format(self.confidence_threshold,self.threshold_updated_count))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Omniscient Policy / Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Oracle :\n",
    "    \"\"\"\n",
    "    It has the optimal parameters to maximize rewards. The learning algorithm updates its parameters to emulate its parameters\n",
    "    It is an omniscient policy that knows all of the probability distributions. This is the algorithm which, every step of \n",
    "    the way, makes the best decision based on its knowledge of the true distributions (it does not have to learn anything). \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initalizes parameters for the omniscient policy. \n",
    "        \"\"\"\n",
    "#         self.rounds = 0 # Number of round played\n",
    "#         self.rounds_data = pd.DataFrame() # Rounds data required for Skip Algorithm\n",
    "    \n",
    "    def setParameters(self, features , arms): # Setting optimal parameter theta\n",
    "        \"\"\"\n",
    "        Sets the optimal parameters for the omniscient policy. \n",
    "        \"\"\"\n",
    "        parameters = np.random.uniform(size=(len(arms) , len(features)))\n",
    "        # Normalize parameters\n",
    "        for i in range(parameters.shape[0]): # Have it in a list comprehension.\n",
    "            parameters[i] = parameters[i] / np.sum(parameters[i])\n",
    "        self.theta_df = pd.DataFrame(data = parameters ,  index = arms , columns = features , dtype= np.float)\n",
    "    \n",
    "    def expectedPayoff(self,contexts,arms):\n",
    "        \"\"\"\n",
    "        Gives the max expected pay-off for a round with the given context & available arms. The arm is not pulled up here as we \n",
    "        also depend of the decision from the skip classifer before the arm is actually pulled.         \n",
    "        \n",
    "        Input : \n",
    "        \n",
    "        contexts : Contextual data available in the round. Its a combination of student & content context\n",
    "        arms : Arms / Content available in this round. \n",
    "        \n",
    "        Returns : \n",
    "        \n",
    "        arm_pulled : The arm that should be pulled \n",
    "        expected_payoff : Expected pay-off for the pulled suggested to be pulled. \n",
    "        \n",
    "        \"\"\"\n",
    "        arms_payoff = list()\n",
    "        for arm in arms:\n",
    "            arm_theta = self.theta_df.loc[arm]\n",
    "            X = contexts.loc[arm]\n",
    "            pta = pd.Series.dot(X,arm_theta) # Vector dim : (1 * d) (d * 1).\n",
    "            arms_payoff.append(pta)\n",
    "#         for i in range(len(arms_payoff)): # Normalize arms_payoff. Required for cases when alpha > 1. Have it in a list comprehension.\n",
    "#             arms_payoff[i] = arms_payoff[i] / np.sum(arms_payoff)\n",
    "        arm_index = np.argmax(arms_payoff)\n",
    "        arm_pulled = arms[arm_index]\n",
    "        expected_payoff = np.max(arms_payoff)\n",
    "        return arm_pulled,np.round(expected_payoff,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 rounds completed\n",
      "self.confidence_threshold : 89.77117175026231 and self.threshold_updated_count : 2\n",
      "self.confidence_threshold : 44.78881127772551 and self.threshold_updated_count : 3\n",
      "102 rounds completed\n",
      "202 rounds completed\n",
      "302 rounds completed\n",
      "402 rounds completed\n",
      "502 rounds completed\n",
      "602 rounds completed\n",
      "702 rounds completed\n",
      "802 rounds completed\n",
      "902 rounds completed\n",
      "self.confidence_threshold : 14.927443870172556 and self.threshold_updated_count : 4\n",
      "1002 rounds completed\n",
      "1102 rounds completed\n",
      "1202 rounds completed\n",
      "1302 rounds completed\n",
      "1402 rounds completed\n",
      "1502 rounds completed\n",
      "1602 rounds completed\n",
      "1702 rounds completed\n",
      "1802 rounds completed\n",
      "1902 rounds completed\n",
      "2002 rounds completed\n",
      "2102 rounds completed\n",
      "2202 rounds completed\n",
      "2302 rounds completed\n",
      "2402 rounds completed\n",
      "2502 rounds completed\n",
      "2602 rounds completed\n",
      "2702 rounds completed\n",
      "2802 rounds completed\n",
      "2902 rounds completed\n",
      "3002 rounds completed\n",
      "3102 rounds completed\n",
      "3202 rounds completed\n",
      "3302 rounds completed\n",
      "3402 rounds completed\n",
      "3502 rounds completed\n",
      "3602 rounds completed\n",
      "3702 rounds completed\n",
      "3802 rounds completed\n",
      "3902 rounds completed\n",
      "4002 rounds completed\n",
      "4102 rounds completed\n",
      "4202 rounds completed\n",
      "4302 rounds completed\n",
      "4402 rounds completed\n",
      "4502 rounds completed\n",
      "4602 rounds completed\n",
      "4702 rounds completed\n",
      "4802 rounds completed\n",
      "4902 rounds completed\n",
      "5002 rounds completed\n",
      "5102 rounds completed\n",
      "5202 rounds completed\n",
      "5302 rounds completed\n",
      "5402 rounds completed\n",
      "5502 rounds completed\n",
      "5602 rounds completed\n",
      "5702 rounds completed\n",
      "5802 rounds completed\n",
      "5902 rounds completed\n",
      "6002 rounds completed\n",
      "6102 rounds completed\n",
      "6202 rounds completed\n",
      "6302 rounds completed\n",
      "6402 rounds completed\n",
      "6502 rounds completed\n",
      "6602 rounds completed\n",
      "6702 rounds completed\n",
      "6802 rounds completed\n",
      "6902 rounds completed\n",
      "7002 rounds completed\n",
      "7102 rounds completed\n",
      "7202 rounds completed\n",
      "7302 rounds completed\n",
      "7402 rounds completed\n",
      "7502 rounds completed\n",
      "7602 rounds completed\n",
      "7702 rounds completed\n",
      "7802 rounds completed\n",
      "7902 rounds completed\n",
      "8002 rounds completed\n",
      "8102 rounds completed\n",
      "8202 rounds completed\n",
      "8302 rounds completed\n",
      "8402 rounds completed\n",
      "8502 rounds completed\n",
      "8602 rounds completed\n",
      "8702 rounds completed\n",
      "8802 rounds completed\n",
      "8902 rounds completed\n",
      "9002 rounds completed\n",
      "9102 rounds completed\n",
      "9202 rounds completed\n",
      "9302 rounds completed\n",
      "9402 rounds completed\n",
      "9502 rounds completed\n",
      "9602 rounds completed\n",
      "9702 rounds completed\n",
      "9802 rounds completed\n",
      "9902 rounds completed\n",
      "self.confidence_threshold : 3.731820451843148 and self.threshold_updated_count : 5\n",
      "10002 rounds completed\n",
      "10102 rounds completed\n",
      "10202 rounds completed\n",
      "10302 rounds completed\n",
      "10402 rounds completed\n",
      "10502 rounds completed\n",
      "10602 rounds completed\n",
      "10702 rounds completed\n",
      "10802 rounds completed\n",
      "10902 rounds completed\n",
      "11002 rounds completed\n",
      "11102 rounds completed\n",
      "11202 rounds completed\n",
      "11302 rounds completed\n",
      "11402 rounds completed\n",
      "11502 rounds completed\n",
      "11602 rounds completed\n",
      "11702 rounds completed\n",
      "11802 rounds completed\n",
      "11902 rounds completed\n",
      "12002 rounds completed\n",
      "12102 rounds completed\n",
      "12202 rounds completed\n",
      "12302 rounds completed\n",
      "12402 rounds completed\n",
      "12502 rounds completed\n",
      "12602 rounds completed\n",
      "12702 rounds completed\n",
      "12802 rounds completed\n",
      "12902 rounds completed\n",
      "13002 rounds completed\n",
      "13102 rounds completed\n",
      "13202 rounds completed\n",
      "13302 rounds completed\n",
      "13402 rounds completed\n",
      "13502 rounds completed\n",
      "13602 rounds completed\n",
      "13702 rounds completed\n",
      "13802 rounds completed\n",
      "13902 rounds completed\n",
      "14002 rounds completed\n",
      "14102 rounds completed\n",
      "14202 rounds completed\n",
      "14302 rounds completed\n",
      "14402 rounds completed\n",
      "14502 rounds completed\n",
      "14602 rounds completed\n",
      "14702 rounds completed\n",
      "14802 rounds completed\n",
      "14902 rounds completed\n",
      "15002 rounds completed\n",
      "15102 rounds completed\n",
      "15202 rounds completed\n",
      "15302 rounds completed\n",
      "15402 rounds completed\n",
      "15502 rounds completed\n",
      "15602 rounds completed\n",
      "15702 rounds completed\n",
      "15802 rounds completed\n",
      "15902 rounds completed\n",
      "16002 rounds completed\n",
      "16102 rounds completed\n",
      "16202 rounds completed\n",
      "16302 rounds completed\n",
      "16402 rounds completed\n",
      "16502 rounds completed\n",
      "16602 rounds completed\n",
      "16702 rounds completed\n",
      "16802 rounds completed\n",
      "16902 rounds completed\n",
      "17002 rounds completed\n",
      "17102 rounds completed\n",
      "17202 rounds completed\n",
      "17302 rounds completed\n",
      "17402 rounds completed\n",
      "17502 rounds completed\n",
      "17602 rounds completed\n",
      "17702 rounds completed\n",
      "17802 rounds completed\n",
      "17902 rounds completed\n",
      "18002 rounds completed\n",
      "18102 rounds completed\n",
      "18202 rounds completed\n",
      "18302 rounds completed\n",
      "18402 rounds completed\n",
      "18502 rounds completed\n",
      "18602 rounds completed\n",
      "18702 rounds completed\n",
      "18802 rounds completed\n",
      "18902 rounds completed\n",
      "19002 rounds completed\n",
      "19102 rounds completed\n",
      "19202 rounds completed\n",
      "19302 rounds completed\n",
      "19402 rounds completed\n",
      "19502 rounds completed\n",
      "19602 rounds completed\n",
      "19702 rounds completed\n",
      "19802 rounds completed\n",
      "19902 rounds completed\n",
      "20002 rounds completed\n",
      "20102 rounds completed\n",
      "20202 rounds completed\n",
      "20302 rounds completed\n",
      "20402 rounds completed\n",
      "20502 rounds completed\n",
      "20602 rounds completed\n",
      "20702 rounds completed\n",
      "20802 rounds completed\n",
      "20902 rounds completed\n",
      "21002 rounds completed\n",
      "21102 rounds completed\n",
      "21202 rounds completed\n",
      "21302 rounds completed\n",
      "21402 rounds completed\n",
      "21502 rounds completed\n",
      "21602 rounds completed\n",
      "21702 rounds completed\n",
      "21802 rounds completed\n",
      "21902 rounds completed\n",
      "22002 rounds completed\n",
      "22102 rounds completed\n",
      "22202 rounds completed\n",
      "22302 rounds completed\n",
      "22402 rounds completed\n",
      "22502 rounds completed\n",
      "22602 rounds completed\n",
      "22702 rounds completed\n",
      "22802 rounds completed\n",
      "22902 rounds completed\n",
      "23002 rounds completed\n",
      "23102 rounds completed\n",
      "23202 rounds completed\n",
      "23302 rounds completed\n",
      "23402 rounds completed\n",
      "23502 rounds completed\n",
      "23602 rounds completed\n",
      "23702 rounds completed\n",
      "23802 rounds completed\n",
      "23902 rounds completed\n",
      "24002 rounds completed\n",
      "24102 rounds completed\n",
      "24202 rounds completed\n",
      "24302 rounds completed\n",
      "24402 rounds completed\n",
      "24502 rounds completed\n",
      "24602 rounds completed\n",
      "24702 rounds completed\n",
      "24802 rounds completed\n",
      "24902 rounds completed\n",
      "25002 rounds completed\n",
      "25102 rounds completed\n",
      "25202 rounds completed\n",
      "25302 rounds completed\n",
      "25402 rounds completed\n",
      "25502 rounds completed\n",
      "25602 rounds completed\n",
      "25702 rounds completed\n",
      "25802 rounds completed\n",
      "25902 rounds completed\n",
      "26002 rounds completed\n",
      "26102 rounds completed\n",
      "26202 rounds completed\n",
      "26302 rounds completed\n",
      "26402 rounds completed\n",
      "26502 rounds completed\n",
      "26602 rounds completed\n",
      "26702 rounds completed\n",
      "26802 rounds completed\n",
      "26902 rounds completed\n",
      "27002 rounds completed\n",
      "27102 rounds completed\n",
      "27202 rounds completed\n",
      "27302 rounds completed\n",
      "27402 rounds completed\n",
      "27502 rounds completed\n",
      "27602 rounds completed\n",
      "27702 rounds completed\n",
      "27802 rounds completed\n",
      "27902 rounds completed\n",
      "28002 rounds completed\n",
      "28102 rounds completed\n",
      "28202 rounds completed\n",
      "28302 rounds completed\n",
      "28402 rounds completed\n",
      "28502 rounds completed\n",
      "28602 rounds completed\n",
      "28702 rounds completed\n",
      "28802 rounds completed\n",
      "28902 rounds completed\n",
      "29002 rounds completed\n",
      "29102 rounds completed\n",
      "29202 rounds completed\n",
      "29302 rounds completed\n",
      "29402 rounds completed\n",
      "29502 rounds completed\n",
      "29602 rounds completed\n",
      "29702 rounds completed\n",
      "29802 rounds completed\n",
      "29902 rounds completed\n",
      "30002 rounds completed\n",
      "30102 rounds completed\n",
      "30202 rounds completed\n",
      "30302 rounds completed\n",
      "30402 rounds completed\n",
      "30502 rounds completed\n",
      "30602 rounds completed\n",
      "30702 rounds completed\n",
      "30802 rounds completed\n",
      "30902 rounds completed\n",
      "31002 rounds completed\n",
      "31102 rounds completed\n",
      "31202 rounds completed\n",
      "31302 rounds completed\n",
      "31402 rounds completed\n",
      "31502 rounds completed\n",
      "31602 rounds completed\n",
      "31702 rounds completed\n",
      "31802 rounds completed\n",
      "31902 rounds completed\n",
      "32002 rounds completed\n",
      "32102 rounds completed\n",
      "32202 rounds completed\n",
      "32302 rounds completed\n",
      "32402 rounds completed\n",
      "32502 rounds completed\n",
      "32602 rounds completed\n",
      "32702 rounds completed\n",
      "32802 rounds completed\n",
      "32902 rounds completed\n",
      "33002 rounds completed\n",
      "33102 rounds completed\n",
      "33202 rounds completed\n",
      "33302 rounds completed\n",
      "33402 rounds completed\n",
      "33502 rounds completed\n",
      "33602 rounds completed\n",
      "33702 rounds completed\n",
      "33802 rounds completed\n",
      "33902 rounds completed\n",
      "34002 rounds completed\n",
      "34102 rounds completed\n",
      "34202 rounds completed\n",
      "34302 rounds completed\n",
      "34402 rounds completed\n",
      "34502 rounds completed\n",
      "34602 rounds completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34702 rounds completed\n",
      "34802 rounds completed\n",
      "34902 rounds completed\n",
      "35002 rounds completed\n",
      "35102 rounds completed\n",
      "35202 rounds completed\n",
      "35302 rounds completed\n",
      "35402 rounds completed\n",
      "35502 rounds completed\n",
      "35602 rounds completed\n",
      "35702 rounds completed\n",
      "35802 rounds completed\n",
      "35902 rounds completed\n",
      "36002 rounds completed\n",
      "36102 rounds completed\n",
      "36202 rounds completed\n",
      "36302 rounds completed\n",
      "36402 rounds completed\n",
      "36502 rounds completed\n",
      "36602 rounds completed\n",
      "36702 rounds completed\n",
      "36802 rounds completed\n",
      "36902 rounds completed\n",
      "37002 rounds completed\n",
      "37102 rounds completed\n",
      "37202 rounds completed\n",
      "37302 rounds completed\n",
      "37402 rounds completed\n",
      "37502 rounds completed\n",
      "37602 rounds completed\n",
      "37702 rounds completed\n",
      "37802 rounds completed\n",
      "37902 rounds completed\n",
      "38002 rounds completed\n",
      "38102 rounds completed\n",
      "38202 rounds completed\n",
      "38302 rounds completed\n",
      "38402 rounds completed\n",
      "38502 rounds completed\n",
      "38602 rounds completed\n",
      "38702 rounds completed\n",
      "38802 rounds completed\n",
      "38902 rounds completed\n",
      "39002 rounds completed\n",
      "39102 rounds completed\n",
      "39202 rounds completed\n",
      "39302 rounds completed\n",
      "39402 rounds completed\n",
      "39502 rounds completed\n",
      "39602 rounds completed\n",
      "39702 rounds completed\n",
      "39802 rounds completed\n",
      "39902 rounds completed\n",
      "40002 rounds completed\n",
      "40102 rounds completed\n",
      "40202 rounds completed\n",
      "40302 rounds completed\n",
      "40402 rounds completed\n",
      "40502 rounds completed\n",
      "40602 rounds completed\n",
      "40702 rounds completed\n",
      "40802 rounds completed\n",
      "40902 rounds completed\n",
      "41002 rounds completed\n",
      "41102 rounds completed\n",
      "41202 rounds completed\n",
      "41302 rounds completed\n",
      "41402 rounds completed\n",
      "41502 rounds completed\n",
      "41602 rounds completed\n",
      "41702 rounds completed\n",
      "41802 rounds completed\n",
      "41902 rounds completed\n",
      "42002 rounds completed\n",
      "42102 rounds completed\n",
      "42202 rounds completed\n",
      "42302 rounds completed\n",
      "42402 rounds completed\n",
      "42502 rounds completed\n",
      "42602 rounds completed\n",
      "42702 rounds completed\n",
      "42802 rounds completed\n",
      "42902 rounds completed\n",
      "43002 rounds completed\n",
      "43102 rounds completed\n",
      "43202 rounds completed\n",
      "43302 rounds completed\n",
      "43402 rounds completed\n",
      "43502 rounds completed\n",
      "43602 rounds completed\n",
      "43702 rounds completed\n",
      "43802 rounds completed\n",
      "43902 rounds completed\n",
      "44002 rounds completed\n",
      "44102 rounds completed\n",
      "44202 rounds completed\n",
      "44302 rounds completed\n",
      "44402 rounds completed\n",
      "44502 rounds completed\n",
      "44602 rounds completed\n",
      "44702 rounds completed\n",
      "44802 rounds completed\n",
      "44902 rounds completed\n",
      "45002 rounds completed\n",
      "45102 rounds completed\n",
      "45202 rounds completed\n",
      "45302 rounds completed\n",
      "45402 rounds completed\n",
      "45502 rounds completed\n",
      "45602 rounds completed\n",
      "45702 rounds completed\n",
      "45802 rounds completed\n",
      "45902 rounds completed\n",
      "46002 rounds completed\n",
      "46102 rounds completed\n",
      "46202 rounds completed\n",
      "46302 rounds completed\n",
      "46402 rounds completed\n",
      "46502 rounds completed\n",
      "46602 rounds completed\n",
      "46702 rounds completed\n",
      "46802 rounds completed\n",
      "46902 rounds completed\n",
      "47002 rounds completed\n",
      "47102 rounds completed\n",
      "47202 rounds completed\n",
      "47302 rounds completed\n",
      "47402 rounds completed\n",
      "47502 rounds completed\n",
      "47602 rounds completed\n",
      "47702 rounds completed\n",
      "47802 rounds completed\n",
      "47902 rounds completed\n",
      "48002 rounds completed\n",
      "48102 rounds completed\n",
      "48202 rounds completed\n",
      "48302 rounds completed\n",
      "48402 rounds completed\n",
      "48502 rounds completed\n",
      "48602 rounds completed\n",
      "48702 rounds completed\n",
      "48802 rounds completed\n",
      "48902 rounds completed\n",
      "49002 rounds completed\n",
      "49102 rounds completed\n",
      "49202 rounds completed\n",
      "49302 rounds completed\n",
      "49402 rounds completed\n",
      "49502 rounds completed\n",
      "49602 rounds completed\n",
      "49702 rounds completed\n",
      "49802 rounds completed\n",
      "49902 rounds completed\n",
      "50002 rounds completed\n",
      "50102 rounds completed\n",
      "50202 rounds completed\n",
      "50302 rounds completed\n",
      "50402 rounds completed\n",
      "50502 rounds completed\n",
      "50602 rounds completed\n",
      "50702 rounds completed\n",
      "50802 rounds completed\n",
      "50902 rounds completed\n",
      "51002 rounds completed\n",
      "51102 rounds completed\n",
      "51202 rounds completed\n",
      "51302 rounds completed\n",
      "51402 rounds completed\n",
      "51502 rounds completed\n",
      "51602 rounds completed\n",
      "51702 rounds completed\n",
      "51802 rounds completed\n",
      "51902 rounds completed\n",
      "52002 rounds completed\n",
      "52102 rounds completed\n",
      "52202 rounds completed\n",
      "52302 rounds completed\n",
      "52402 rounds completed\n",
      "52502 rounds completed\n",
      "52602 rounds completed\n",
      "52702 rounds completed\n",
      "52802 rounds completed\n",
      "52902 rounds completed\n",
      "53002 rounds completed\n",
      "53102 rounds completed\n",
      "53202 rounds completed\n",
      "53302 rounds completed\n",
      "53402 rounds completed\n",
      "53502 rounds completed\n",
      "53602 rounds completed\n",
      "53702 rounds completed\n",
      "53802 rounds completed\n",
      "53902 rounds completed\n",
      "54002 rounds completed\n",
      "54102 rounds completed\n",
      "54202 rounds completed\n",
      "54302 rounds completed\n",
      "54402 rounds completed\n",
      "54502 rounds completed\n",
      "54602 rounds completed\n",
      "54702 rounds completed\n",
      "54802 rounds completed\n",
      "54902 rounds completed\n",
      "55002 rounds completed\n",
      "55102 rounds completed\n",
      "55202 rounds completed\n",
      "55302 rounds completed\n",
      "55402 rounds completed\n",
      "55502 rounds completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _get_module_lock.<locals>.cb at 0x7fd4f47bb0d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen importlib._bootstrap>\", line 191, in cb\n",
      "KeyError: 'pandas._libs.pandas.core.dtypes.cast'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55602 rounds completed\n",
      "55702 rounds completed\n",
      "55802 rounds completed\n",
      "55902 rounds completed\n",
      "56002 rounds completed\n",
      "56102 rounds completed\n",
      "56202 rounds completed\n",
      "56302 rounds completed\n",
      "56402 rounds completed\n",
      "56502 rounds completed\n",
      "56602 rounds completed\n",
      "56702 rounds completed\n",
      "56802 rounds completed\n",
      "56902 rounds completed\n",
      "57002 rounds completed\n",
      "57102 rounds completed\n",
      "57202 rounds completed\n",
      "57302 rounds completed\n",
      "57402 rounds completed\n",
      "57502 rounds completed\n",
      "57602 rounds completed\n",
      "57702 rounds completed\n",
      "57802 rounds completed\n",
      "57902 rounds completed\n",
      "58002 rounds completed\n",
      "58102 rounds completed\n",
      "58202 rounds completed\n",
      "58302 rounds completed\n",
      "58402 rounds completed\n",
      "58502 rounds completed\n",
      "58602 rounds completed\n",
      "58702 rounds completed\n",
      "58802 rounds completed\n",
      "58902 rounds completed\n",
      "59002 rounds completed\n",
      "59102 rounds completed\n",
      "59202 rounds completed\n",
      "59302 rounds completed\n",
      "59402 rounds completed\n",
      "59502 rounds completed\n",
      "59602 rounds completed\n",
      "59702 rounds completed\n",
      "59802 rounds completed\n",
      "59902 rounds completed\n",
      "60002 rounds completed\n",
      "60102 rounds completed\n",
      "60202 rounds completed\n",
      "60302 rounds completed\n",
      "60402 rounds completed\n",
      "60502 rounds completed\n",
      "60602 rounds completed\n",
      "60702 rounds completed\n",
      "60802 rounds completed\n",
      "60902 rounds completed\n",
      "61002 rounds completed\n",
      "61102 rounds completed\n",
      "61202 rounds completed\n",
      "61302 rounds completed\n",
      "61402 rounds completed\n",
      "61502 rounds completed\n",
      "61602 rounds completed\n",
      "61702 rounds completed\n",
      "61802 rounds completed\n",
      "61902 rounds completed\n",
      "62002 rounds completed\n",
      "62102 rounds completed\n",
      "62202 rounds completed\n",
      "62302 rounds completed\n",
      "62402 rounds completed\n",
      "62502 rounds completed\n",
      "62602 rounds completed\n",
      "62702 rounds completed\n",
      "62802 rounds completed\n",
      "62902 rounds completed\n",
      "63002 rounds completed\n",
      "63102 rounds completed\n",
      "63202 rounds completed\n",
      "63302 rounds completed\n",
      "63402 rounds completed\n",
      "63502 rounds completed\n",
      "63602 rounds completed\n",
      "63702 rounds completed\n",
      "63802 rounds completed\n",
      "63902 rounds completed\n",
      "64002 rounds completed\n",
      "64102 rounds completed\n",
      "64202 rounds completed\n",
      "64302 rounds completed\n",
      "64402 rounds completed\n",
      "64502 rounds completed\n",
      "64602 rounds completed\n",
      "64702 rounds completed\n",
      "64802 rounds completed\n",
      "64902 rounds completed\n",
      "65002 rounds completed\n",
      "65102 rounds completed\n",
      "65202 rounds completed\n",
      "65302 rounds completed\n",
      "65402 rounds completed\n",
      "65502 rounds completed\n",
      "65602 rounds completed\n",
      "65702 rounds completed\n",
      "65802 rounds completed\n",
      "65902 rounds completed\n",
      "66002 rounds completed\n",
      "66102 rounds completed\n",
      "66202 rounds completed\n",
      "66302 rounds completed\n",
      "66402 rounds completed\n",
      "66502 rounds completed\n",
      "66602 rounds completed\n",
      "66702 rounds completed\n",
      "66802 rounds completed\n",
      "66902 rounds completed\n",
      "67002 rounds completed\n",
      "67102 rounds completed\n",
      "67202 rounds completed\n",
      "67302 rounds completed\n",
      "67402 rounds completed\n",
      "67502 rounds completed\n",
      "67602 rounds completed\n",
      "67702 rounds completed\n",
      "67802 rounds completed\n",
      "67902 rounds completed\n",
      "68002 rounds completed\n",
      "68102 rounds completed\n",
      "68202 rounds completed\n",
      "68302 rounds completed\n",
      "68402 rounds completed\n",
      "68502 rounds completed\n",
      "68602 rounds completed\n",
      "68702 rounds completed\n",
      "68802 rounds completed\n",
      "68902 rounds completed\n",
      "69002 rounds completed\n",
      "69102 rounds completed\n",
      "69202 rounds completed\n",
      "69302 rounds completed\n",
      "69402 rounds completed\n",
      "69502 rounds completed\n",
      "69602 rounds completed\n",
      "69702 rounds completed\n",
      "69802 rounds completed\n",
      "69902 rounds completed\n",
      "70002 rounds completed\n",
      "70102 rounds completed\n",
      "70202 rounds completed\n",
      "70302 rounds completed\n",
      "70402 rounds completed\n",
      "70502 rounds completed\n",
      "70602 rounds completed\n",
      "70702 rounds completed\n",
      "70802 rounds completed\n",
      "Total Number of rounds :  70813\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "class Simulator:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.context = Context()\n",
    "        self.context.setStudentContext()\n",
    "        self.context.setContentContext()\n",
    "        self.context.setTopic()\n",
    "        self.context.setTopicContent()\n",
    "        self.oracle = Oracle()\n",
    "        self.skipTopic = SkipTopic()\n",
    "        self.simulator_lock = threading.Lock()\n",
    "        self.rounds=0\n",
    "        self.rounds_interval = 1\n",
    "#         self.logs = pd.DataFrame(columns = ['student_number','topic','arm_pulled','reward']) \n",
    "\n",
    "        self.logs = pd.DataFrame(columns = ['student_number','topic','arm_pulled','pay-off','pay-off_next_topic','actual_decision','skip_decision','skip_enabled'\n",
    "                                            ,'reward']) \n",
    "\n",
    "\n",
    "    def getPayoff(self,pta):\n",
    "        \"\"\"\n",
    "        Student shares feedback about the content / understanding of the topic. \n",
    "        \n",
    "        Input : \n",
    "        \n",
    "        pta : Payoff at round 't' for pulling an arm. \n",
    "        \n",
    "        Returns : \n",
    "        \n",
    "        reward : Reward / Feedback from student for the content shown / arm pulled\n",
    "        \"\"\"\n",
    "        reward = bernoulli.rvs(size=1,p=pta)[0] # Simulate student's response\n",
    "#         if reward == 0:\n",
    "#             reward = -1\n",
    "        return reward\n",
    "    \n",
    "    def takeCourse(self,student_number,studentContext,contentContext,topic,topic_content):\n",
    "        \"\"\"\n",
    "        This method simulates students taking a course. As part of it, students are presented content for various topics. \n",
    "        Students share their feedback, based on which we either move to the next topic or remain on the same topic.  \n",
    "        We get the expected pay-off from the oracle. We then decide whether to skip or remain on the same topic.\n",
    "        If skip is true, then the student moves to the next topic, else the student remains on the same topic, shares feedback on \n",
    "        the content & we train the skip classifier with this feedback. This method drives the flow of the system, hence key \n",
    "        data elements available in this method are logged for analysis.\n",
    "        \n",
    "        Inputs : \n",
    "        \n",
    "        student_number : Student Id \n",
    "        studentContext : Student context vector. \n",
    "        contentContext : Contents context. This has context of all contents for the topic. \n",
    "        topic : All the topics to be taught as part of the course. \n",
    "        topic_content : Relates all topics to the contents available for every topic     \n",
    "         \n",
    "        \"\"\"\n",
    "        for i in topic:\n",
    "            skip_enabled = False # Done to disable skipping without attempting to teach a student. \n",
    "            contents = topic_content[i] # You now have all arm associated with the topic 't'\n",
    "            t_c = contentContext.loc[contents]\n",
    "            contexts = self.context.prepareContext(studentContext,t_c)\n",
    "            arms = list(t_c.index)\n",
    "            while arms:\n",
    "                arm , pta = self.oracle.expectedPayoff(contexts,arms)\n",
    "                actual_decision , confidence_score, skip_decision , pta_next_topic = self.skipTopic.skipTopic(studentContext,pta,i,self.context,topic_content,self.oracle)\n",
    "                if skip_decision and skip_enabled:\n",
    "                    log = pd.Series([student_number,i,arm,pta,pta_next_topic,actual_decision,confidence_score,skip_decision,skip_enabled], \n",
    "                                        index=['student_number','topic','arm_pulled','pay-off',\n",
    "                                                'pay-off_next_topic','actual_decision','confidence_score','skip_decision','skip_enabled']) # Print log for this round\n",
    "                    with self.simulator_lock:\n",
    "#                         print('We\\'re skipping. Student {0} is on topic {1} was expected to be shown content {2}. Expected Pay-off of this arm is {3}, compared to expected pay-off of next round is {4}. Actual decision was {5} with confidence {6} Decision of skip classifier is {7}'\n",
    "#                           .format(student_number,i,arm,pta,pta_next_topic,actual_decision,confidence_score,skip_decision))                    \n",
    "                        self.logs = self.logs.append(log , ignore_index=True) # Log in a file\n",
    "                    break # Decision is to skip. Hence, we won't pull the arm. \n",
    "                else:\n",
    "                    actual_payoff = self.getPayoff(pta)\n",
    "#                 log = pd.Series([student_number,i,arm,actual_payoff], \n",
    "#                                 index=['student_number','topic','arm_pulled','reward']) # Print log for this round\n",
    "                    log = pd.Series([student_number,i,arm,pta,pta_next_topic,actual_decision,confidence_score,skip_decision,skip_enabled,actual_payoff], \n",
    "                                        index=['student_number','topic','arm_pulled','pay-off',\n",
    "                                                'pay-off_next_topic','actual_decision','confidence_score','skip_decision','skip_enabled','reward']) # Print log for this round\n",
    "                    with self.simulator_lock:\n",
    "                        self.rounds+=1\n",
    "                        if self.rounds > self.rounds_interval:\n",
    "                            print('{0} rounds completed'.format(self.rounds))\n",
    "                            self.rounds_interval += 100                        \n",
    "#                         print('Student {0} is on topic {1} is shown content {2} feedback recd is {3}.'\n",
    "#                                   .format(student_number,i,arm,actual_payoff))\n",
    "#                         self.logs = self.logs.append(log , ignore_index=True) # Log in a file\n",
    "#                         print('Student {0} is on topic {1} is shown content {2} feedback recd is {3}. Expected Pay-off of this arm is {4}, compared to expected pay-off of next round is {5}. Actual decision was {6} with confidence {7}. Decision of skip classifier is {8} and skipping is {9}.'\n",
    "#                               .format(student_number,i,arm,actual_payoff,pta,pta_next_topic,actual_decision,confidence_score,skip_decision,skip_enabled))\n",
    "                        self.logs = self.logs.append(log , ignore_index=True) # Log in a file\n",
    "                    label = self.skipTopic.setLabel(actual_payoff) # Set Label\n",
    "                    self.skipTopic.train(studentContext,pta,pta_next_topic,label)\n",
    "                    self.skipTopic.updateConfidenceThreshold(self.rounds)\n",
    "                if actual_payoff != 1:\n",
    "                    arms.remove(arm)\n",
    "                    skip_enabled = True\n",
    "                else:\n",
    "                    break # Move to the next topic \n",
    "\n",
    "    def main(self):\n",
    "        \"\"\"\n",
    "        Its the main method. Its in the name :)\n",
    "        \"\"\"\n",
    "        studentContext = self.context.getStudentContext() # Student dataframe\n",
    "        contentContext = self.context.getContentContext() # Content Dataframe\n",
    "        topic = self.context.getTopic() # List of topics. \n",
    "        topic_content = self.context.getTopicContent() # Topics Data, which includes topics to content mapping.\n",
    "        features = list(studentContext.columns) + list(contentContext.columns)\n",
    "        self.oracle.setParameters(features , contentContext.index) \n",
    "        student_thread = list() # Keep track of students taking the course. \n",
    "        for student_number , student in studentContext.iterrows():\n",
    "            t = threading.Thread(target=self.takeCourse, args=(student_number,student,contentContext,topic,topic_content))\n",
    "            student_thread.append(t)\n",
    "            # Some threads do background tasks, like sending keepalive packets, or performing periodic garbage collection, or \n",
    "            # whatever. These are only useful when the main program is running, and it's okay to kill them off once the other, \n",
    "            # non-daemon, threads have exited. Once the main thread finishes & one of the student is still working through the course. \n",
    "            # we will wait for the student to complete the course, since the main thread is completed. We want all students \n",
    "            # to complete the course. Hence, setting daemon to False\n",
    "            t.daemon = False # classifying as a daemon, so they will die when the main dies\n",
    "            t.start() # begins, must come after daemon definition\n",
    "        for t in student_thread: # This is done to ensure, we proceed to save the logs only after all students have completed the course. \n",
    "            t.join()\n",
    "        self.logs.to_csv('logs_oracle_large',index=False)\n",
    "        print('Total Number of rounds : ', self.rounds)  \n",
    "    \n",
    "simulator = Simulator()\n",
    "simulator.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reward_not_0 = pd.read_csv('logs_oracle_medium_CT10_Topics10')\n",
    "# reward_not_0 = pd.read_csv('logs_linUCB_verySmall_0.001')\n",
    "reward_not_0 = pd.read_csv('logs_oracle_verySmall')\n",
    "len(reward_not_0['arm_pulled'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'logs_oracle_small' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-c366215ebe99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logs_oracle_small'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#df[df['confidence_score'] > 25]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'student_number'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'logs_oracle_small' does not exist"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('logs_oracle_small')\n",
    "#df[df['confidence_score'] > 25]\n",
    "df[df['student_number'] == 8]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the reward as -1 & 1. \n",
    "\n",
    "We now, penalize arms for their wrong predictions. For every wrong prediction, we set the reward as -1, instead of 0. A unique advantage of this is that more content items are explored. This is because, now the expected pay-off of a content item reduces for a wrong prediction. This was not the case earlier, as we did not penalize content items for not getting a reward. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
